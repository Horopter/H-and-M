{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a407fa8b",
   "metadata": {},
   "source": [
    "# HVSM: TF\u2013IDF + XGBoost + Logistic Regression (CV & Tuning)\n\nThis notebook upgrades your baseline pipeline to hit higher macro-F1\nwith stratified k-fold CV, tuning, and expanded diagnostics, while remaining OOM-aware.\n\n**Inputs (strict):** `data/train.csv`, `data/val.csv`, `data/test.csv` in the `data/` folder. `data/test.csv` must have `id` and no `label`. The notebook creates `outputs/submission_hvsm_prod_1.csv`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0532c8b5",
   "metadata": {},
   "source": [
    "## Imports and guardrails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfdf051",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\nimport os, re, warnings\nimport gc\nimport time\nfrom typing import List, Tuple, Dict, Optional\nfrom dataclasses import dataclass\nfrom datetime import datetime\nfrom collections import Counter\nimport numpy as np, pandas as pd\nfrom tqdm import tqdm\nfrom scipy.sparse import hstack, csr_matrix\nfrom scipy import stats\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.metrics import (accuracy_score, classification_report,\n    f1_score, roc_auc_score, roc_curve, precision_recall_curve,\n    confusion_matrix)\nfrom sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\nfrom xgboost import XGBClassifier\nimport matplotlib.pyplot as plt\ntry:\n    import seaborn as sns\nexcept Exception:\n    sns = None\ntry:\n    from textblob import TextBlob\nexcept Exception:\n    TextBlob = None\n    warnings.warn('TextBlob missing; sentiment features set to zeros.')\nnp.set_printoptions(linewidth=79)\npd.set_option('display.width', 79)\npd.set_option('display.max_columns', 40)\nRANDOM_SEED = 42\nrng = np.random.default_rng(RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2dab59",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c19b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    tfidf_max_features: int = 50000\n",
    "    tfidf_ngram_max: int = 3\n",
    "    use_char_ngrams: bool = False\n",
    "    min_df: int = 2\n",
    "    kfolds: int = 5\n",
    "    xgb_iter: int = 25\n",
    "    lr_iter: int = 25\n",
    "    plot_level: str = 'full'\n",
    "CFG = Config()\n",
    "print(CFG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1e303a",
   "metadata": {},
   "source": [
    "## Plotting helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c919db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gc() -> None:\n    gc.collect()\n\n\n_STEP_STARTS = {}\n\ndef log_step(msg: str) -> None:\n    ts = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n    print(f\"[{ts}] {msg}\", flush=True)\n\ndef log_step_start(name: str) -> None:\n    _STEP_STARTS[name] = time.perf_counter()\n    log_step(f\"START: {name}\")\n\ndef log_step_end(name: str) -> None:\n    start = _STEP_STARTS.pop(name, None)\n    if start is None:\n        log_step(f\"END: {name}\")\n    else:\n        elapsed = time.perf_counter() - start\n        log_step(f\"END: {name} (elapsed {elapsed:.1f}s)\")\n\n\ndef predict_proba_chunks(model, X, chunk_size: int = 50000) -> np.ndarray:\n    n = X.shape[0]\n    out = np.empty(n, dtype=np.float32)\n    for start in range(0, n, chunk_size):\n        end = min(start + chunk_size, n)\n        out[start:end] = model.predict_proba(X[start:end])[:, 1]\n    return out\n\n\ndef _tight() -> None:\n    plt.tight_layout()\ndef qq_plot(residuals: np.ndarray, title: str) -> None:\n    plt.figure(figsize=(5, 4)); stats.probplot(residuals, dist='norm',\n                                               plot=plt)\n    plt.title(title); _tight(); plt.show()\ndef residual_plot(y_true: np.ndarray, y_prob: np.ndarray,\n                  title: str) -> None:\n    resid = y_true - y_prob\n    plt.figure(figsize=(5, 4)); plt.scatter(y_prob, resid, s=8)\n    plt.axhline(0.0, linestyle='--'); plt.xlabel('p(y=1)');\n    plt.ylabel('residual'); plt.title(title); _tight(); plt.show()\ndef violin_by_label(df: pd.DataFrame, label_col: str, feat_col: str,\n                    title: str) -> None:\n    if sns is None:\n        df.boxplot(column=feat_col, by=label_col, figsize=(5, 4))\n        plt.title(title); plt.suptitle(''); _tight(); plt.show(); return\n    plt.figure(figsize=(5, 4));\n    sns.violinplot(data=df, x=label_col, y=feat_col)\n    plt.title(title); _tight(); plt.show()\ndef plot_roc_pr(y_true: np.ndarray, y_prob: np.ndarray, title: str)->None:\n    fpr, tpr, _ = roc_curve(y_true, y_prob)\n    prec, rec, _ = precision_recall_curve(y_true, y_prob)\n    fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n    ax[0].plot(fpr, tpr)\n    ax[0].set_title(f'ROC AUC={roc_auc_score(y_true, y_prob):.3f}')\n    ax[0].set_xlabel('FPR'); ax[0].set_ylabel('TPR')\n    ax[1].plot(rec, prec); ax[1].set_title('Precision\u2013Recall')\n    ax[1].set_xlabel('Recall'); ax[1].set_ylabel('Precision')\n    _tight(); plt.show()\ndef plot_confusion(y_true: np.ndarray, y_hat: np.ndarray, title: str)->None:\n    cm = confusion_matrix(y_true, y_hat)\n    plt.figure(figsize=(4, 3)); plt.imshow(cm, cmap='Blues')\n    plt.title(title); plt.colorbar()\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            plt.text(j, i, int(cm[i, j]), ha='center', va='center')\n    plt.xlabel('Pred'); plt.ylabel('True'); _tight(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f43999",
   "metadata": {},
   "source": [
    "## Processing and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73aa79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start('Processing and feature engineering')\n",
    "def _ttr(text: str) -> float:\n    words = re.findall(r'\\S+', text.lower())\n    return float(len(set(words)) / len(words)) if words else 0.0\ndef _sentiment(df: pd.DataFrame) -> pd.DataFrame:\n    if TextBlob is None:\n        df['sentiment_polarity'] = 0.0\n        df['sentiment_subjectivity'] = 0.0\n        return df\n    tqdm.pandas()\n    df['sentiment_polarity'] = df['text'].progress_apply(\n        lambda x: float(TextBlob(x).sentiment.polarity))\n    df['sentiment_subjectivity'] = df['text'].progress_apply(\n        lambda x: float(TextBlob(x).sentiment.subjectivity))\n    return df\ndef process_text_file(filename: str) -> pd.DataFrame:\n    df = pd.read_csv(os.path.join(filename))\n    assert 'text' in df.columns, 'CSV must contain a text column.'\n    df['text'] = df['text'].astype(str)\n    df['text_length'] = df['text'].str.len()\n    df['word_count'] = df['text'].str.split().str.len()\n    df['sentence_count'] = df['text'].str.count(r'[.!?]+').replace(0, 1)\n    df['avg_sentence_length'] = (\n        (df['word_count']/df['sentence_count']).clip(upper=100))\n    df['punct_count'] = df['text'].str.count(r'[^\\w\\s]')\n    df['punct_ratio'] = (\n        (df['punct_count']/df['text_length']).clip(0, 0.3))\n    df['ttr'] = df['text'].apply(_ttr)\n    df['digit_ratio'] = df['text'].str.count(r'\\d') / (\n        df['text_length'].replace(0, 1))\n    df['upper_ratio'] = df['text'].str.count(r'[A-Z]') / (\n        df['text_length'].replace(0, 1))\n    df['bangs'] = df['text'].str.count(r'!')\n    df['questions'] = df['text'].str.count(r'\\?')\n    return df\n",
    "log_step_end('Processing and feature engineering')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1f0aa5",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c84d6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start('Load data')\ntrain = process_text_file('data/train.csv')\nval = process_text_file('data/val.csv')\ntest = process_text_file('data/test.csv')\nassert 'label' in train.columns and 'label' in val.columns\nassert 'label' not in test.columns\nassert 'id' in test.columns\nprint('Rows:', len(train), len(val), len(test))\nlog_step_end('Load data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affdb891",
   "metadata": {},
   "source": [
    "## Sentiment features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba07a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start('Sentiment features')\n",
    "train = _sentiment(train); val = _sentiment(val); test = _sentiment(test)\n",
    "log_step_end('Sentiment features')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b8e010",
   "metadata": {},
   "source": [
    "## Numeric and TF\u2013IDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c42f57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start('Numeric and TF\u2013IDF features')\n",
    "feature_cols: List[str] = [\n    'text_length','word_count','ttr','sentence_count','avg_sentence_length',\n    'punct_ratio','sentiment_polarity','sentiment_subjectivity',\n    'digit_ratio','upper_ratio','bangs','questions'\n]\nXtr_basic = csr_matrix(train[feature_cols].to_numpy(dtype=np.float32))\nXva_basic = csr_matrix(val[feature_cols].to_numpy(dtype=np.float32))\nXte_basic = csr_matrix(test[feature_cols].to_numpy(dtype=np.float32))\nvec_word = TfidfVectorizer(ngram_range=(1, 3), max_features=50000,\n                           min_df=2, stop_words='english', dtype=np.float32)\nXtr_w = vec_word.fit_transform(train['text'])\nXva_w = vec_word.transform(val['text'])\nXte_w = vec_word.transform(test['text'])\nX_train = hstack([Xtr_basic, Xtr_w])\nX_val = hstack([Xva_basic, Xva_w])\nX_test = hstack([Xte_basic, Xte_w])\ny_train = train['label'].astype(int).values\ny_val = val['label'].astype(int).values\nprint('Shapes:', X_train.shape, X_val.shape, X_test.shape)\n_gc()\n",
    "log_step_end('Numeric and TF\u2013IDF features')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d868d0f",
   "metadata": {},
   "source": [
    "## Stratified k-fold CV + tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2901045",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start('Stratified k-fold CV + tuning')\ndef _xgb_space() -> Dict[str, List]:\n    return {\n        'n_estimators': list(range(300, 901, 100)),\n        'max_depth': list(range(3, 9)),\n        'learning_rate': [0.03, 0.05, 0.07, 0.1],\n        'subsample': [0.7, 0.8, 0.9, 1.0],\n        'colsample_bytree': [0.6, 0.8, 1.0],\n        'reg_alpha': [0.0, 0.1, 0.5, 1.0],\n        'reg_lambda': [0.5, 1.0, 1.5, 2.0],\n    }\ndef _lr_space() -> Dict[str, List]:\n    return {\n        'C': [0.1, 0.3, 1.0, 3.0, 10.0],\n        'penalty': ['l2'],\n        'solver': ['liblinear', 'lbfgs'],\n        'class_weight': [None, 'balanced'],\n    }\ndef tune_xgb(X, y) -> XGBClassifier:\n    base = XGBClassifier(random_state=42, eval_metric='logloss',\n                         tree_method='hist', n_jobs=1)\n    rs = RandomizedSearchCV(base, _xgb_space(), n_iter=25, scoring='f1',\n                            n_jobs=1, cv=5, verbose=3, random_state=42,\n                            pre_dispatch=1,\n                            refit=True)\n    log_step_start('XGB randomized search')\n    rs.fit(X, y)\n    log_step_end('XGB randomized search')\n    print('Best XGB params:', rs.best_params_)\n    return rs.best_estimator_\ndef tune_lr(X, y) -> LogisticRegression:\n    base = LogisticRegression(max_iter=2000, random_state=42)\n    rs = RandomizedSearchCV(base, _lr_space(), n_iter=25, scoring='f1',\n                            n_jobs=1, cv=5, verbose=3, random_state=42,\n                            pre_dispatch=1,\n                            refit=True)\n    log_step_start('LR randomized search')\n    rs.fit(X, y)\n    log_step_end('LR randomized search')\n    print('Best LR params:', rs.best_params_)\n    return rs.best_estimator_\nxgb_tuned = tune_xgb(X_train, y_train)\nlr_tuned = tune_lr(X_train, y_train)\n_gc()\nlog_step_end('Stratified k-fold CV + tuning')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb30f46",
   "metadata": {},
   "source": [
    "## Fit final models and calibrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ffc914",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start('Fit final models and calibrate')\nfrom scipy.sparse import vstack\nX_trval = vstack([X_train, X_val])\ny_trval = np.concatenate([y_train, y_val])\nlog_step_start('Fold 1/1 (single split)')\nlog_step_start('XGB training epochs')\nxgb_tuned.fit(X_trval, y_trval, eval_set=[(X_val, y_val)], verbose=True)\nlog_step_end('XGB training epochs')\nlog_step_start('LR fit')\nlr_tuned.fit(X_trval, y_trval)\nlog_step_end('LR fit')\nlog_step_end('Fold 1/1 (single split)')\ncal_xgb = CalibratedClassifierCV(xgb_tuned, method='sigmoid',\n                                 cv='prefit')\ncal_xgb.fit(X_val, y_val)\ncal_lr = CalibratedClassifierCV(lr_tuned, method='sigmoid', cv='prefit')\ncal_lr.fit(X_val, y_val)\n_gc()\nlog_step_end('Fit final models and calibrate')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfe7e8f",
   "metadata": {},
   "source": [
    "## Ensemble and threshold tuning on val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2176f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start('Ensemble and threshold tuning on val')\n",
    "p_xgb = cal_xgb.predict_proba(X_val)[:, 1]\np_lr = cal_lr.predict_proba(X_val)[:, 1]\nbest_w, best_f1, best_thr = 0.5, -1.0, 0.5\nfor w in np.linspace(0.0, 1.0, 21):\n    p = w * p_xgb + (1.0 - w) * p_lr\n    for thr in np.arange(0.1, 0.91, 0.01):\n        yhat = (p >= thr).astype(int)\n        f1 = f1_score(y_val, yhat)\n        if f1 > best_f1:\n            best_w, best_f1, best_thr = float(w), float(f1), float(thr)\nprint(f'Ensemble w={best_w:.2f} thr={best_thr:.2f} F1={best_f1:.4f}')\n",
    "log_step_end('Ensemble and threshold tuning on val')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4aacd3",
   "metadata": {},
   "source": [
    "## Validation diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c533a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start('Validation diagnostics')\n",
    "p_ens = best_w * p_xgb + (1.0 - best_w) * p_lr\nyhat_val = (p_ens >= best_thr).astype(int)\nprint(classification_report(y_val, yhat_val))\nresidual_plot(y_val, p_ens, 'Residuals: validation ensemble')\nqq_plot(y_val - p_ens, 'QQ: residuals (validation)')\nplot_roc_pr(y_val, p_ens, 'Validation ROC/PR (ensemble)')\nplot_confusion(y_val, yhat_val, 'Confusion (validation)')\nviolin_by_label(train, 'label', 'text_length', 'Text length by label')\n",
    "log_step_end('Validation diagnostics')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e00c4f",
   "metadata": {},
   "source": [
    "## Feature importance snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c26e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start('Feature importance snapshots')\n",
    "try:\n    booster = xgb_tuned.get_booster()\n    scores = booster.get_score(importance_type='gain')\n    items = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n    print('Top 25 XGB features by gain:')\n    for k, v in items[:25]:\n        print(f'{k}: {v:.4f}')\nexcept Exception as e:\n    warnings.warn(f'XGB importance unavailable: {e}')\ntry:\n    if hasattr(lr_tuned, 'coef_'):\n        coef = lr_tuned.coef_.ravel()\n        idx = np.argsort(np.abs(coef))[::-1][:25]\n        print('Top 25 |coef| for LR: indices and values:')\n        for i in idx:\n            print(i, float(coef[i]))\nexcept Exception as e:\n    warnings.warn(f'LR coef summary failed: {e}')\n",
    "log_step_end('Feature importance snapshots')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404d4521",
   "metadata": {},
   "source": [
    "## Predict on test and save submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a07b275",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start('Predict on test and save submission')\n",
    "p_xgb_te = predict_proba_chunks(cal_xgb, X_test)\np_lr_te = predict_proba_chunks(cal_lr, X_test)\np_ens_te = best_w * p_xgb_te + (1.0 - best_w) * p_lr_te\nyhat_te = (p_ens_te >= best_thr).astype(int)\nsubmission = pd.DataFrame({'id': test['id'], 'label': yhat_te})\noutputs_dir = 'outputs'\nos.makedirs(outputs_dir, exist_ok=True)\nsubmission_path = os.path.join(outputs_dir, 'submission_hvsm_prod_1.csv')\nsubmission.to_csv(submission_path, index=False)\nprint('Saved', submission_path, 'with', len(submission), 'rows')\n_gc()\n",
    "log_step_end('Predict on test and save submission')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772f3b67",
   "metadata": {},
   "source": [
    "## Final checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0d8a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start('Final checks')\n",
    "assert submission['label'].isin([0, 1]).all()\nprint('Done. All checks passed.')\n",
    "log_step_end('Final checks')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}