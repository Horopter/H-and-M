{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f94205bb65a84986b8096842865058df",
   "metadata": {},
   "source": [
    "# HVSM Notebook: hvsm_prod_1.ipynb\n",
    "\n",
    "- Runs with: slurm_scripts/hvsm_job_1.sh\n",
    "- Purpose: CPU TF-IDF + XGBoost/LR with CV tuning and diagnostics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceb42cec1c7418da2199a507be7c653",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters (papermill)\n",
    "DATA_DIR = \"data\"\n",
    "TRAIN_CSV = \"data/train.csv\"\n",
    "VAL_CSV = \"data/val.csv\"\n",
    "TEST_CSV = \"data/test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a407fa8b",
   "metadata": {},
   "source": [
    "# HVSM: TF\u2013IDF + XGBoost + Logistic Regression (CV & Tuning)\n\nThis notebook upgrades your baseline pipeline to hit higher macro-F1\nwith stratified k-fold CV, tuning, and expanded diagnostics, while remaining OOM-aware.\n\n**Inputs (strict):** `data/train.csv`, `data/val.csv`, `data/test.csv` in the `data/` folder. `data/test.csv` must have `id` and no `label`. The notebook creates `outputs/submission_hvsm_prod_1.csv`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0532c8b5",
   "metadata": {},
   "source": [
    "## Imports and guardrails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfdf051",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import os, re, warnings, json, hashlib, inspect, joblib\n",
    "import gc\n",
    "import time\n",
    "from typing import List, Dict\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from scipy import stats\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    precision_recall_curve,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.model_selection import ParameterSampler, StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    import seaborn as sns\n",
    "except Exception:\n",
    "    sns = None\n",
    "try:\n",
    "    from textblob import TextBlob\n",
    "except Exception:\n",
    "    TextBlob = None\n",
    "    warnings.warn(\"TextBlob missing; sentiment features set to zeros.\")\n",
    "np.set_printoptions(linewidth=79)\n",
    "pd.set_option(\"display.width\", 79)\n",
    "pd.set_option(\"display.max_columns\", 40)\n",
    "RANDOM_SEED = 42\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2dab59",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c19b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    tfidf_max_features: int = 40000\n",
    "    tfidf_ngram_max: int = 11\n",
    "    use_char_ngrams: bool = False\n",
    "    min_df: int = 2\n",
    "    kfolds: int = 3\n",
    "    xgb_iter: int = 8\n",
    "    lr_iter: int = 8\n",
    "    plot_level: str = \"full\"\n",
    "\n",
    "\n",
    "CFG = Config()\n",
    "print(CFG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1e303a",
   "metadata": {},
   "source": [
    "## Plotting helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c919db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gc() -> None:\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "_STEP_STARTS = {}\n",
    "\n",
    "\n",
    "def log_step(msg: str) -> None:\n",
    "    ts = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"[{ts}] {msg}\", flush=True)\n",
    "\n",
    "\n",
    "def log_step_start(name: str) -> None:\n",
    "    _STEP_STARTS[name] = time.perf_counter()\n",
    "    log_step(f\"START: {name}\")\n",
    "\n",
    "\n",
    "def log_step_end(name: str) -> None:\n",
    "    start = _STEP_STARTS.pop(name, None)\n",
    "    if start is None:\n",
    "        log_step(f\"END: {name}\")\n",
    "    else:\n",
    "        elapsed = time.perf_counter() - start\n",
    "        log_step(f\"END: {name} (elapsed {elapsed:.1f}s)\")\n",
    "\n",
    "\n",
    "def predict_proba_chunks(model, X, chunk_size: int = 50000) -> np.ndarray:\n",
    "    n = X.shape[0]\n",
    "    out = np.empty(n, dtype=np.float32)\n",
    "    for start in range(0, n, chunk_size):\n",
    "        end = min(start + chunk_size, n)\n",
    "        out[start:end] = model.predict_proba(X[start:end])[:, 1]\n",
    "    return out\n",
    "\n",
    "\n",
    "def _tight() -> None:\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "def qq_plot(residuals: np.ndarray, title: str) -> None:\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "    plt.title(title)\n",
    "    _tight()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def residual_plot(y_true: np.ndarray, y_prob: np.ndarray, title: str) -> None:\n",
    "    resid = y_true - y_prob\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.scatter(y_prob, resid, s=8)\n",
    "    plt.axhline(0.0, linestyle=\"--\")\n",
    "    plt.xlabel(\"p(y=1)\")\n",
    "    plt.ylabel(\"residual\")\n",
    "    plt.title(title)\n",
    "    _tight()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def violin_by_label(\n",
    "    df: pd.DataFrame, label_col: str, feat_col: str, title: str\n",
    ") -> None:\n",
    "    if sns is None:\n",
    "        df.boxplot(column=feat_col, by=label_col, figsize=(5, 4))\n",
    "        plt.title(title)\n",
    "        plt.suptitle(\"\")\n",
    "        _tight()\n",
    "        plt.show()\n",
    "        return\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.violinplot(data=df, x=label_col, y=feat_col)\n",
    "    plt.title(title)\n",
    "    _tight()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_roc_pr(y_true: np.ndarray, y_prob: np.ndarray, title: str) -> None:\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "    prec, rec, _ = precision_recall_curve(y_true, y_prob)\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    ax[0].plot(fpr, tpr)\n",
    "    ax[0].set_title(f\"ROC AUC={roc_auc_score(y_true, y_prob):.3f}\")\n",
    "    ax[0].set_xlabel(\"FPR\")\n",
    "    ax[0].set_ylabel(\"TPR\")\n",
    "    ax[1].plot(rec, prec)\n",
    "    ax[1].set_title(\"Precision\u2013Recall\")\n",
    "    ax[1].set_xlabel(\"Recall\")\n",
    "    ax[1].set_ylabel(\"Precision\")\n",
    "    _tight()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_confusion(y_true: np.ndarray, y_hat: np.ndarray, title: str) -> None:\n",
    "    cm = confusion_matrix(y_true, y_hat)\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    plt.imshow(cm, cmap=\"Blues\")\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, int(cm[i, j]), ha=\"center\", va=\"center\")\n",
    "    plt.xlabel(\"Pred\")\n",
    "    plt.ylabel(\"True\")\n",
    "    _tight()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f43999",
   "metadata": {},
   "source": [
    "## Processing and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73aa79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start(\"Processing and feature engineering\")\n",
    "\n",
    "\n",
    "def _ttr(text: str) -> float:\n",
    "    words = re.findall(r\"\\S+\", text.lower())\n",
    "    return float(len(set(words)) / len(words)) if words else 0.0\n",
    "\n",
    "\n",
    "def _sentiment(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if TextBlob is None:\n",
    "        df[\"sentiment_polarity\"] = 0.0\n",
    "        df[\"sentiment_subjectivity\"] = 0.0\n",
    "        return df\n",
    "    tqdm.pandas()\n",
    "    df[\"sentiment_polarity\"] = df[\"text\"].progress_apply(\n",
    "        lambda x: float(TextBlob(x).sentiment.polarity)\n",
    "    )\n",
    "    df[\"sentiment_subjectivity\"] = df[\"text\"].progress_apply(\n",
    "        lambda x: float(TextBlob(x).sentiment.subjectivity)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def process_text_file(filename: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(os.path.join(filename))\n",
    "    assert \"text\" in df.columns, \"CSV must contain a text column.\"\n",
    "    df[\"text\"] = df[\"text\"].astype(str)\n",
    "    df[\"text_length\"] = df[\"text\"].str.len()\n",
    "    df[\"word_count\"] = df[\"text\"].str.split().str.len()\n",
    "    df[\"sentence_count\"] = df[\"text\"].str.count(r\"[.!?]+\").replace(0, 1)\n",
    "    df[\"avg_sentence_length\"] = (df[\"word_count\"] / df[\"sentence_count\"]).clip(\n",
    "        upper=100\n",
    "    )\n",
    "    df[\"punct_count\"] = df[\"text\"].str.count(r\"[^\\w\\s]\")\n",
    "    df[\"punct_ratio\"] = (df[\"punct_count\"] / df[\"text_length\"]).clip(0, 0.3)\n",
    "    df[\"ttr\"] = df[\"text\"].apply(_ttr)\n",
    "    df[\"digit_ratio\"] = df[\"text\"].str.count(r\"\\d\") / (\n",
    "        df[\"text_length\"].replace(0, 1)\n",
    "    )\n",
    "    df[\"upper_ratio\"] = df[\"text\"].str.count(r\"[A-Z]\") / (\n",
    "        df[\"text_length\"].replace(0, 1)\n",
    "    )\n",
    "    df[\"bangs\"] = df[\"text\"].str.count(r\"!\")\n",
    "    df[\"questions\"] = df[\"text\"].str.count(r\"\\?\")\n",
    "    return df\n",
    "\n",
    "\n",
    "log_step_end(\"Processing and feature engineering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1f0aa5",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c84d6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start(\"Load data\")\n",
    "\n",
    "from pathlib import Path\n",
    "import hashlib\n",
    "\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "if not (PROJECT_ROOT / DATA_DIR).exists():\n",
    "    for parent in PROJECT_ROOT.parents:\n",
    "        if (parent / DATA_DIR).exists():\n",
    "            PROJECT_ROOT = parent\n",
    "            break\n",
    "\n",
    "\n",
    "def resolve_path(path_str: str) -> str:\n",
    "    p = Path(path_str)\n",
    "    if p.is_absolute():\n",
    "        return str(p)\n",
    "    if p.parent == Path(\".\"):\n",
    "        data_dir = Path(DATA_DIR)\n",
    "        if not data_dir.is_absolute():\n",
    "            data_dir = PROJECT_ROOT / data_dir\n",
    "        candidate = data_dir / p.name\n",
    "        if candidate.exists():\n",
    "            return str(candidate)\n",
    "    return str((PROJECT_ROOT / p).resolve())\n",
    "\n",
    "\n",
    "# Reassemble chunked CSVs if needed\n",
    "def ensure_chunked_csv(path: Path) -> None:\n",
    "    if path.exists():\n",
    "        return\n",
    "    parts = sorted(path.parent.glob(path.name + \".part*\"))\n",
    "    if not parts:\n",
    "        raise FileNotFoundError(f\"Missing {path} and no chunk files found.\")\n",
    "    tmp_path = path.with_suffix(path.suffix + \".tmp\")\n",
    "    if tmp_path.exists():\n",
    "        tmp_path.unlink()\n",
    "    hasher = hashlib.sha256()\n",
    "    with tmp_path.open(\"wb\") as out:\n",
    "        for part in parts:\n",
    "            with part.open(\"rb\") as f:\n",
    "                while True:\n",
    "                    chunk = f.read(1024 * 1024)\n",
    "                    if not chunk:\n",
    "                        break\n",
    "                    out.write(chunk)\n",
    "                    hasher.update(chunk)\n",
    "    sha_path = path.with_suffix(path.suffix + \".sha256\")\n",
    "    if sha_path.exists():\n",
    "        expected = sha_path.read_text().split()[0]\n",
    "        actual = hasher.hexdigest()\n",
    "        if expected != actual:\n",
    "            tmp_path.unlink(missing_ok=True)\n",
    "            raise ValueError(\n",
    "                f\"SHA256 mismatch for {path}: expected {expected} got {actual}\"\n",
    "            )\n",
    "    tmp_path.replace(path)\n",
    "    log_step(f\"Reassembled {path} from {len(parts)} chunks.\")\n",
    "\n",
    "\n",
    "train_path = Path(resolve_path(TRAIN_CSV))\n",
    "val_path = Path(resolve_path(VAL_CSV))\n",
    "test_path = Path(resolve_path(TEST_CSV))\n",
    "ensure_chunked_csv(train_path)\n",
    "ensure_chunked_csv(val_path)\n",
    "ensure_chunked_csv(test_path)\n",
    "\n",
    "train = process_text_file(str(train_path))\n",
    "val = process_text_file(str(val_path))\n",
    "test = process_text_file(str(test_path))\n",
    "assert \"label\" in train.columns and \"label\" in val.columns\n",
    "assert \"label\" not in test.columns\n",
    "assert \"id\" in test.columns\n",
    "print(\"Rows:\", len(train), len(val), len(test))\n",
    "log_step_end(\"Load data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affdb891",
   "metadata": {},
   "source": [
    "## Sentiment features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba07a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start(\"Sentiment features\")\n",
    "train = _sentiment(train)\n",
    "val = _sentiment(val)\n",
    "test = _sentiment(test)\n",
    "log_step_end(\"Sentiment features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b8e010",
   "metadata": {},
   "source": [
    "## Numeric and TF\u2013IDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c42f57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start(\"Numeric and TF\u2013IDF features\")\n",
    "feature_cols: List[str] = [\n",
    "    \"text_length\",\n",
    "    \"word_count\",\n",
    "    \"ttr\",\n",
    "    \"sentence_count\",\n",
    "    \"avg_sentence_length\",\n",
    "    \"punct_ratio\",\n",
    "    \"sentiment_polarity\",\n",
    "    \"sentiment_subjectivity\",\n",
    "    \"digit_ratio\",\n",
    "    \"upper_ratio\",\n",
    "    \"bangs\",\n",
    "    \"questions\",\n",
    "]\n",
    "Xtr_basic = csr_matrix(train[feature_cols].to_numpy(dtype=np.float32))\n",
    "Xva_basic = csr_matrix(val[feature_cols].to_numpy(dtype=np.float32))\n",
    "Xte_basic = csr_matrix(test[feature_cols].to_numpy(dtype=np.float32))\n",
    "vec_word = TfidfVectorizer(\n",
    "    ngram_range=(1, 11),\n",
    "    max_features=50000,\n",
    "    min_df=2,\n",
    "    stop_words=\"english\",\n",
    "    dtype=np.float32,\n",
    ")\n",
    "Xtr_w = vec_word.fit_transform(train[\"text\"])\n",
    "Xva_w = vec_word.transform(val[\"text\"])\n",
    "Xte_w = vec_word.transform(test[\"text\"])\n",
    "X_train = hstack([Xtr_basic, Xtr_w])\n",
    "X_val = hstack([Xva_basic, Xva_w])\n",
    "X_test = hstack([Xte_basic, Xte_w])\n",
    "y_train = train[\"label\"].astype(int).values\n",
    "y_val = val[\"label\"].astype(int).values\n",
    "print(\"Shapes:\", X_train.shape, X_val.shape, X_test.shape)\n",
    "_gc()\n",
    "log_step_end(\"Numeric and TF\u2013IDF features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d868d0f",
   "metadata": {},
   "source": [
    "## Stratified k-fold CV + tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2901045",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start(\"Stratified k-fold CV + tuning\")\n",
    "\n",
    "\n",
    "def _xgb_space() -> Dict[str, List]:\n",
    "    return {\n",
    "        \"n_estimators\": [500],\n",
    "        \"max_depth\": list(range(3, 8)),\n",
    "        \"learning_rate\": [0.03, 0.05, 0.07, 0.1],\n",
    "        \"subsample\": [0.7, 0.8, 0.9],\n",
    "        \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "        \"reg_alpha\": [0.0, 0.1, 0.5],\n",
    "        \"reg_lambda\": [0.5, 1.0, 1.5],\n",
    "    }\n",
    "\n",
    "\n",
    "def _lr_space() -> Dict[str, List]:\n",
    "    return {\n",
    "        \"C\": [0.1, 0.3, 1.0, 3.0, 10.0],\n",
    "        \"penalty\": [\"l2\"],\n",
    "        \"solver\": [\"liblinear\", \"lbfgs\"],\n",
    "        \"class_weight\": [None, \"balanced\"],\n",
    "    }\n",
    "\n",
    "\n",
    "def _search_signature(param_distributions, n_iter, kfolds, random_state, X_shape):\n",
    "    payload = {\n",
    "        \"param_distributions\": param_distributions,\n",
    "        \"n_iter\": n_iter,\n",
    "        \"kfolds\": kfolds,\n",
    "        \"random_state\": random_state,\n",
    "        \"X_shape\": list(X_shape),\n",
    "    }\n",
    "    raw = json.dumps(payload, sort_keys=True, default=str)\n",
    "    return hashlib.md5(raw.encode()).hexdigest()[:10]\n",
    "\n",
    "\n",
    "def _load_results(results_path: Path):\n",
    "    rows = []\n",
    "    if not results_path.exists():\n",
    "        return rows\n",
    "    with results_path.open() as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                rows.append(json.loads(line))\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "    return rows\n",
    "\n",
    "\n",
    "def _checkpointed_random_search(\n",
    "    estimator_factory,\n",
    "    param_distributions,\n",
    "    X,\n",
    "    y,\n",
    "    n_iter,\n",
    "    kfolds,\n",
    "    random_state,\n",
    "    search_name,\n",
    "):\n",
    "    ckpt_dir = Path(PROJECT_ROOT) / \"checkpoints\"\n",
    "    ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
    "    sig = _search_signature(\n",
    "        param_distributions, n_iter, kfolds, random_state, X.shape\n",
    "    )\n",
    "    candidates_path = ckpt_dir / f\"{search_name}_{sig}_candidates.json\"\n",
    "    results_path = ckpt_dir / f\"{search_name}_{sig}_results.jsonl\"\n",
    "    meta_path = ckpt_dir / f\"{search_name}_{sig}_meta.json\"\n",
    "\n",
    "    if candidates_path.exists():\n",
    "        candidates = json.loads(candidates_path.read_text())\n",
    "    else:\n",
    "        candidates = list(\n",
    "            ParameterSampler(\n",
    "                param_distributions, n_iter=n_iter, random_state=random_state\n",
    "            )\n",
    "        )\n",
    "        candidates_path.write_text(json.dumps(candidates, indent=2))\n",
    "\n",
    "    meta_path.write_text(\n",
    "        json.dumps(\n",
    "            {\n",
    "                \"signature\": sig,\n",
    "                \"n_iter\": n_iter,\n",
    "                \"kfolds\": kfolds,\n",
    "                \"random_state\": random_state,\n",
    "                \"X_shape\": list(X.shape),\n",
    "                \"n_candidates\": len(candidates),\n",
    "            },\n",
    "            indent=2,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    rows = _load_results(results_path)\n",
    "    scores_by_cand = {}\n",
    "    done = set()\n",
    "    for row in rows:\n",
    "        cand = row.get(\"cand_idx\")\n",
    "        fold = row.get(\"fold_idx\")\n",
    "        status = row.get(\"status\")\n",
    "        if cand is None or fold is None:\n",
    "            continue\n",
    "        cand = int(cand)\n",
    "        fold = int(fold)\n",
    "        if status == \"ok\":\n",
    "            scores_by_cand.setdefault(cand, {})[fold] = float(\n",
    "                row.get(\"score\", 0.0)\n",
    "            )\n",
    "        if status in (\"ok\", \"fail\"):\n",
    "            done.add((cand, fold))\n",
    "\n",
    "    completed = sum(\n",
    "        1 for scores in scores_by_cand.values() if len(scores) == kfolds\n",
    "    )\n",
    "    if rows:\n",
    "        print(\n",
    "            f\"Resuming {search_name}: {completed}/{len(candidates)} \"\n",
    "            \"candidates fully scored.\"\n",
    "        )\n",
    "\n",
    "    splits = list(\n",
    "        StratifiedKFold(\n",
    "            n_splits=kfolds, shuffle=True, random_state=random_state\n",
    "        ).split(X, y)\n",
    "    )\n",
    "\n",
    "    best_score = -1.0\n",
    "    best_params = None\n",
    "    for cand_idx, scores in scores_by_cand.items():\n",
    "        if len(scores) == kfolds:\n",
    "            mean = float(np.mean(list(scores.values())))\n",
    "            if mean > best_score:\n",
    "                best_score = mean\n",
    "                best_params = candidates[cand_idx]\n",
    "\n",
    "    with results_path.open(\"a\") as f:\n",
    "        for cand_idx, params in enumerate(candidates):\n",
    "            cand_scores = scores_by_cand.setdefault(cand_idx, {})\n",
    "            if len(cand_scores) == kfolds:\n",
    "                continue\n",
    "            log_step(\n",
    "                f\"{search_name}: candidate {cand_idx + 1}/{len(candidates)}\"\n",
    "            )\n",
    "            for fold_idx, (tr_idx, va_idx) in enumerate(splits):\n",
    "                if (cand_idx, fold_idx) in done:\n",
    "                    continue\n",
    "                start = time.perf_counter()\n",
    "                status = \"ok\"\n",
    "                score = None\n",
    "                error = None\n",
    "                try:\n",
    "                    model = estimator_factory(params)\n",
    "                    model.fit(X[tr_idx], y[tr_idx])\n",
    "                    preds = model.predict(X[va_idx])\n",
    "                    score = float(f1_score(y[va_idx], preds))\n",
    "                    cand_scores[fold_idx] = score\n",
    "                except Exception as exc:\n",
    "                    status = \"fail\"\n",
    "                    error = str(exc)\n",
    "                elapsed = time.perf_counter() - start\n",
    "                record = {\n",
    "                    \"cand_idx\": cand_idx,\n",
    "                    \"fold_idx\": fold_idx,\n",
    "                    \"status\": status,\n",
    "                    \"score\": score,\n",
    "                    \"elapsed_sec\": round(elapsed, 2),\n",
    "                    \"params\": params,\n",
    "                    \"error\": error,\n",
    "                }\n",
    "                f.write(json.dumps(record) + \"\n",
    "\")\n",
    "                f.flush()\n",
    "                os.fsync(f.fileno())\n",
    "                done.add((cand_idx, fold_idx))\n",
    "                if status == \"ok\":\n",
    "                    log_step(\n",
    "                        f\"{search_name} cand {cand_idx + 1} \"\n",
    "                        f\"fold {fold_idx + 1}/{kfolds} f1={score:.4f} \"\n",
    "                        f\"({elapsed / 60:.1f} min)\"\n",
    "                    )\n",
    "                else:\n",
    "                    log_step(\n",
    "                        f\"{search_name} cand {cand_idx + 1} \"\n",
    "                        f\"fold {fold_idx + 1}/{kfolds} failed: {error}\"\n",
    "                    )\n",
    "                _gc()\n",
    "            if len(cand_scores) == kfolds:\n",
    "                mean = float(np.mean(list(cand_scores.values())))\n",
    "                log_step(\n",
    "                    f\"{search_name} candidate {cand_idx + 1} mean f1={mean:.4f}\"\n",
    "                )\n",
    "                if mean > best_score:\n",
    "                    best_score = mean\n",
    "                    best_params = params\n",
    "\n",
    "    if best_params is None:\n",
    "        return None\n",
    "\n",
    "    params_path = ckpt_dir / f\"{search_name}_{sig}_best.json\"\n",
    "    params_path.write_text(\n",
    "        json.dumps(\n",
    "            {\"best_score\": best_score, \"best_params\": best_params}, indent=2\n",
    "        )\n",
    "    )\n",
    "    return best_params\n",
    "\n",
    "\n",
    "def tune_xgb(X, y) -> XGBClassifier:\n",
    "    base_params = {\n",
    "        \"random_state\": 42,\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"max_bin\": 256,\n",
    "        \"n_jobs\": 1,\n",
    "    }\n",
    "    log_step_start(\"XGB randomized search\")\n",
    "    best_params = _checkpointed_random_search(\n",
    "        lambda p: XGBClassifier(**base_params, **p),\n",
    "        _xgb_space(),\n",
    "        X,\n",
    "        y,\n",
    "        n_iter=CFG.xgb_iter,\n",
    "        kfolds=CFG.kfolds,\n",
    "        random_state=42,\n",
    "        search_name=\"xgb_search\",\n",
    "    )\n",
    "    log_step_end(\"XGB randomized search\")\n",
    "    if best_params is None:\n",
    "        warnings.warn(\"XGB search produced no valid candidates; using default.\")\n",
    "        model = XGBClassifier(**base_params)\n",
    "        model.fit(X, y)\n",
    "        return model\n",
    "    model = XGBClassifier(**base_params, **best_params)\n",
    "    log_step_start(\"XGB refit on full data\")\n",
    "    model.fit(X, y)\n",
    "    log_step_end(\"XGB refit on full data\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def tune_lr(X, y) -> LogisticRegression:\n",
    "    base_params = {\n",
    "        \"max_iter\": 2000,\n",
    "        \"random_state\": 42,\n",
    "    }\n",
    "    log_step_start(\"LR randomized search\")\n",
    "    best_params = _checkpointed_random_search(\n",
    "        lambda p: LogisticRegression(**base_params, **p),\n",
    "        _lr_space(),\n",
    "        X,\n",
    "        y,\n",
    "        n_iter=CFG.lr_iter,\n",
    "        kfolds=CFG.kfolds,\n",
    "        random_state=42,\n",
    "        search_name=\"lr_search\",\n",
    "    )\n",
    "    log_step_end(\"LR randomized search\")\n",
    "    if best_params is None:\n",
    "        warnings.warn(\"LR search produced no valid candidates; using default.\")\n",
    "        model = LogisticRegression(**base_params)\n",
    "        model.fit(X, y)\n",
    "        return model\n",
    "    model = LogisticRegression(**base_params, **best_params)\n",
    "    log_step_start(\"LR refit on full data\")\n",
    "    model.fit(X, y)\n",
    "    log_step_end(\"LR refit on full data\")\n",
    "    return model\n",
    "\n",
    "\n",
    "xgb_tuned = tune_xgb(X_train, y_train)\n",
    "lr_tuned = tune_lr(X_train, y_train)\n",
    "_gc()\n",
    "log_step_end(\"Stratified k-fold CV + tuning\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb30f46",
   "metadata": {},
   "source": [
    "## Fit final models and calibrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ffc914",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start(\"Fit final models and calibrate\")\n",
    "from scipy.sparse import vstack\n",
    "\n",
    "ckpt_root = Path(PROJECT_ROOT) if \"PROJECT_ROOT\" in globals() else Path.cwd()\n",
    "ckpt_dir = ckpt_root / \"checkpoints\"\n",
    "ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _model_signature(name, params, X_shape, y_shape):\n",
    "    payload = {\n",
    "        \"name\": name,\n",
    "        \"params\": params,\n",
    "        \"X_shape\": list(X_shape),\n",
    "        \"y_shape\": list(y_shape),\n",
    "    }\n",
    "    raw = json.dumps(payload, sort_keys=True, default=str)\n",
    "    return hashlib.md5(raw.encode()).hexdigest()[:10]\n",
    "\n",
    "X_trval = vstack([X_train, X_val])\n",
    "y_trval = np.concatenate([y_train, y_val])\n",
    "log_step_start(\"Fold 1/1 (single split)\")\n",
    "log_step_start(\"XGB training epochs\")\n",
    "es_rounds = 50\n",
    "fit_kwargs = {\"eval_set\": [(X_val, y_val)], \"verbose\": True}\n",
    "fit_sig = inspect.signature(xgb_tuned.fit)\n",
    "if \"early_stopping_rounds\" in fit_sig.parameters:\n",
    "    fit_kwargs[\"early_stopping_rounds\"] = es_rounds\n",
    "else:\n",
    "    warnings.warn(\n",
    "        \"XGBClassifier.fit does not support early_stopping_rounds; \"\n",
    "        \"running without it.\"\n",
    "    )\n",
    "\n",
    "xgb_params = xgb_tuned.get_params()\n",
    "xgb_sig = _model_signature(\"xgb\", xgb_params, X_trval.shape, y_trval.shape)\n",
    "xgb_ckpt = ckpt_dir / f\"hvsm_prod_1_xgb_{xgb_sig}.joblib\"\n",
    "\n",
    "if xgb_ckpt.exists():\n",
    "    xgb_tuned = joblib.load(xgb_ckpt)\n",
    "    log_step(f\"Loaded XGB checkpoint: {xgb_ckpt}\")\n",
    "else:\n",
    "    xgb_tuned.fit(X_trval, y_trval, **fit_kwargs)\n",
    "    joblib.dump(xgb_tuned, xgb_ckpt)\n",
    "    log_step(f\"Saved XGB checkpoint: {xgb_ckpt}\")\n",
    "log_step_end(\"XGB training epochs\")\n",
    "\n",
    "log_step_start(\"LR fit\")\n",
    "lr_params = lr_tuned.get_params()\n",
    "lr_sig = _model_signature(\"lr\", lr_params, X_trval.shape, y_trval.shape)\n",
    "lr_ckpt = ckpt_dir / f\"hvsm_prod_1_lr_{lr_sig}.joblib\"\n",
    "\n",
    "if lr_ckpt.exists():\n",
    "    lr_tuned = joblib.load(lr_ckpt)\n",
    "    log_step(f\"Loaded LR checkpoint: {lr_ckpt}\")\n",
    "else:\n",
    "    lr_tuned.fit(X_trval, y_trval)\n",
    "    joblib.dump(lr_tuned, lr_ckpt)\n",
    "    log_step(f\"Saved LR checkpoint: {lr_ckpt}\")\n",
    "log_step_end(\"LR fit\")\n",
    "log_step_end(\"Fold 1/1 (single split)\")\n",
    "cal_xgb = CalibratedClassifierCV(xgb_tuned, method=\"sigmoid\", cv=\"prefit\")\n",
    "cal_xgb.fit(X_val, y_val)\n",
    "cal_lr = CalibratedClassifierCV(lr_tuned, method=\"sigmoid\", cv=\"prefit\")\n",
    "cal_lr.fit(X_val, y_val)\n",
    "_gc()\n",
    "log_step_end(\"Fit final models and calibrate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfe7e8f",
   "metadata": {},
   "source": [
    "## Ensemble and threshold tuning on val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2176f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start(\"Ensemble and threshold tuning on val\")\n",
    "p_xgb = cal_xgb.predict_proba(X_val)[:, 1]\n",
    "p_lr = cal_lr.predict_proba(X_val)[:, 1]\n",
    "best_w, best_f1, best_thr = 0.5, -1.0, 0.5\n",
    "for w in np.linspace(0.0, 1.0, 21):\n",
    "    p = w * p_xgb + (1.0 - w) * p_lr\n",
    "    for thr in np.arange(0.1, 0.91, 0.01):\n",
    "        yhat = (p >= thr).astype(int)\n",
    "        f1 = f1_score(y_val, yhat)\n",
    "        if f1 > best_f1:\n",
    "            best_w, best_f1, best_thr = float(w), float(f1), float(thr)\n",
    "print(f\"Ensemble w={best_w:.2f} thr={best_thr:.2f} F1={best_f1:.4f}\")\n",
    "log_step_end(\"Ensemble and threshold tuning on val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4aacd3",
   "metadata": {},
   "source": [
    "## Validation diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c533a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start(\"Validation diagnostics\")\n",
    "p_ens = best_w * p_xgb + (1.0 - best_w) * p_lr\n",
    "yhat_val = (p_ens >= best_thr).astype(int)\n",
    "print(classification_report(y_val, yhat_val))\n",
    "residual_plot(y_val, p_ens, \"Residuals: validation ensemble\")\n",
    "qq_plot(y_val - p_ens, \"QQ: residuals (validation)\")\n",
    "plot_roc_pr(y_val, p_ens, \"Validation ROC/PR (ensemble)\")\n",
    "plot_confusion(y_val, yhat_val, \"Confusion (validation)\")\n",
    "violin_by_label(train, \"label\", \"text_length\", \"Text length by label\")\n",
    "log_step_end(\"Validation diagnostics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e00c4f",
   "metadata": {},
   "source": [
    "## Feature importance snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c26e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start(\"Feature importance snapshots\")\n",
    "try:\n",
    "    booster = xgb_tuned.get_booster()\n",
    "    scores = booster.get_score(importance_type=\"gain\")\n",
    "    items = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    print(\"Top 25 XGB features by gain:\")\n",
    "    for k, v in items[:25]:\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "except Exception as e:\n",
    "    warnings.warn(f\"XGB importance unavailable: {e}\")\n",
    "try:\n",
    "    if hasattr(lr_tuned, \"coef_\"):\n",
    "        coef = lr_tuned.coef_.ravel()\n",
    "        idx = np.argsort(np.abs(coef))[::-1][:25]\n",
    "        print(\"Top 25 |coef| for LR: indices and values:\")\n",
    "        for i in idx:\n",
    "            print(i, float(coef[i]))\n",
    "except Exception as e:\n",
    "    warnings.warn(f\"LR coef summary failed: {e}\")\n",
    "log_step_end(\"Feature importance snapshots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404d4521",
   "metadata": {},
   "source": [
    "## Predict on test and save submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a07b275",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start(\"Predict on test and save submission\")\n",
    "p_xgb_te = predict_proba_chunks(cal_xgb, X_test)\n",
    "p_lr_te = predict_proba_chunks(cal_lr, X_test)\n",
    "p_ens_te = best_w * p_xgb_te + (1.0 - best_w) * p_lr_te\n",
    "yhat_te = (p_ens_te >= best_thr).astype(int)\n",
    "submission = pd.DataFrame({\"id\": test[\"id\"], \"label\": yhat_te})\n",
    "outputs_dir = \"outputs\"\n",
    "os.makedirs(outputs_dir, exist_ok=True)\n",
    "submission_path = os.path.join(outputs_dir, \"submission_hvsm_prod_1.csv\")\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(\"Saved\", submission_path, \"with\", len(submission), \"rows\")\n",
    "_gc()\n",
    "log_step_end(\"Predict on test and save submission\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772f3b67",
   "metadata": {},
   "source": [
    "## Final checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0d8a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start(\"Final checks\")\n",
    "assert submission[\"label\"].isin([0, 1]).all()\n",
    "print(\"Done. All checks passed.\")\n",
    "log_step_end(\"Final checks\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
