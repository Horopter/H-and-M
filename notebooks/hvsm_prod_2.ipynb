{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b624783913d54e99acab16990adbaa99",
   "metadata": {},
   "source": [
    "# HVSM Notebook: hvsm_prod_2.ipynb\n",
    "\n",
    "- Runs with: slurm_scripts/hvsm_job_2.sh\n",
    "- Purpose: CPU TF-IDF + XGBoost/LR with binary rules and prevalence match.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c901c2acfe4a4b81b2ba288e77fa17",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters (papermill)\n",
    "DATA_DIR = \"data\"\n",
    "TRAIN_CSV = \"data/train.csv\"\n",
    "VAL_CSV = \"data/val.csv\"\n",
    "TEST_CSV = \"data/test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2cf675",
   "metadata": {},
   "source": [
    "# HVSM \u2014 TF\u2013IDF + LR/XGB with Binary Rules, CV, and Prevalence Match\n\nInputs: `data/train.csv`, `data/val.csv`, `data/test.csv` in `data/`. `data/test.csv` must have `id` and no `label`. Output: `outputs/submission_hvsm_prod_2.csv`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4d71cc",
   "metadata": {},
   "source": [
    "## Imports and guardrails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468392e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import os, re, string, warnings, json, hashlib\n",
    "import gc\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "from scipy.sparse import csr_matrix, hstack, vstack\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    precision_recall_curve,\n",
    ")\n",
    "from sklearn.model_selection import ParameterSampler, StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost.callback import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    import seaborn as sns\n",
    "except Exception:\n",
    "    sns = None\n",
    "try:\n",
    "    from textblob import TextBlob\n",
    "except Exception:\n",
    "    TextBlob = None\n",
    "    warnings.warn(\"TextBlob missing; sentiment features set to zeros.\")\n",
    "np.set_printoptions(linewidth=79)\n",
    "pd.set_option(\"display.width\", 79)\n",
    "pd.set_option(\"display.max_columns\", 60)\n",
    "RANDOM_SEED = 42\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d366fbf",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42190c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    tfidf_max_features: int = 40000\n",
    "    tfidf_ngram_max: int = 3\n",
    "    use_char_ngrams: bool = False\n",
    "    char_tfidf_max_features: int = 15000\n",
    "    min_df: int = 2\n",
    "    kfolds: int = 3\n",
    "    xgb_iter: int = 8\n",
    "    lr_iter: int = 8\n",
    "    plot_level: str = \"full\"\n",
    "\n",
    "\n",
    "CFG = Config()\n",
    "print(CFG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44654139",
   "metadata": {},
   "source": [
    "## Plotting helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f2237c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gc() -> None:\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "_STEP_STARTS = {}\n",
    "\n",
    "\n",
    "def log_step(msg: str) -> None:\n",
    "    ts = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"[{ts}] {msg}\", flush=True)\n",
    "\n",
    "\n",
    "def log_step_start(name: str) -> None:\n",
    "    _STEP_STARTS[name] = time.perf_counter()\n",
    "    log_step(f\"START: {name}\")\n",
    "\n",
    "\n",
    "def log_step_end(name: str) -> None:\n",
    "    start = _STEP_STARTS.pop(name, None)\n",
    "    if start is None:\n",
    "        log_step(f\"END: {name}\")\n",
    "    else:\n",
    "        elapsed = time.perf_counter() - start\n",
    "        log_step(f\"END: {name} (elapsed {elapsed:.1f}s)\")\n",
    "\n",
    "\n",
    "def predict_proba_chunks(model, X, chunk_size: int = 50000) -> np.ndarray:\n",
    "    n = X.shape[0]\n",
    "    out = np.empty(n, dtype=np.float32)\n",
    "    for start in range(0, n, chunk_size):\n",
    "        end = min(start + chunk_size, n)\n",
    "        out[start:end] = model.predict_proba(X[start:end])[:, 1]\n",
    "    return out\n",
    "\n",
    "\n",
    "def _tight() -> None:\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "def qq_plot(residuals: np.ndarray, title: str) -> None:\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "    plt.title(title)\n",
    "    _tight()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def residual_plot(y_true: np.ndarray, y_prob: np.ndarray, title: str) -> None:\n",
    "    resid = y_true - y_prob\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.scatter(y_prob, resid, s=8)\n",
    "    plt.axhline(0.0, linestyle=\"--\")\n",
    "    plt.xlabel(\"p(y=1)\")\n",
    "    plt.ylabel(\"residual\")\n",
    "    plt.title(title)\n",
    "    _tight()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def violin_by_label(\n",
    "    df: pd.DataFrame, label_col: str, feat_col: str, title: str\n",
    ") -> None:\n",
    "    if sns is None:\n",
    "        df.boxplot(column=feat_col, by=label_col, figsize=(5, 4))\n",
    "        plt.title(title)\n",
    "        plt.suptitle(\"\")\n",
    "        _tight()\n",
    "        plt.show()\n",
    "        return\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.violinplot(data=df, x=label_col, y=feat_col)\n",
    "    plt.title(title)\n",
    "    _tight()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_roc_pr(y_true: np.ndarray, y_prob: np.ndarray, title: str) -> None:\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "    prec, rec, _ = precision_recall_curve(y_true, y_prob)\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    ax[0].plot(fpr, tpr)\n",
    "    ax[0].set_title(f\"ROC AUC={roc_auc_score(y_true, y_prob):.3f}\")\n",
    "    ax[0].set_xlabel(\"FPR\")\n",
    "    ax[0].set_ylabel(\"TPR\")\n",
    "    ax[1].plot(rec, prec)\n",
    "    ax[1].set_title(\"Precision\u2013Recall\")\n",
    "    ax[1].set_xlabel(\"Recall\")\n",
    "    ax[1].set_ylabel(\"Precision\")\n",
    "    _tight()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_confusion(y_true: np.ndarray, y_hat: np.ndarray, title: str) -> None:\n",
    "    cm = confusion_matrix(y_true, y_hat)\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    plt.imshow(cm, cmap=\"Blues\")\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, int(cm[i, j]), ha=\"center\", va=\"center\")\n",
    "    plt.xlabel(\"Pred\")\n",
    "    plt.ylabel(\"True\")\n",
    "    _tight()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca448e3f",
   "metadata": {},
   "source": [
    "## Processing and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba98a859",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start(\"Processing and features\")\n",
    "\n",
    "\n",
    "def _ttr(text: str) -> float:\n",
    "    toks = re.findall(r\"\\S+\", text.lower())\n",
    "    return float(len(set(toks)) / len(toks)) if toks else 0.0\n",
    "\n",
    "\n",
    "def _sentiment(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if TextBlob is None:\n",
    "        df[\"sentiment_polarity\"] = 0.0\n",
    "        df[\"sentiment_subjectivity\"] = 0.0\n",
    "        return df\n",
    "    tqdm.pandas()\n",
    "    df[\"sentiment_polarity\"] = df[\"text\"].progress_apply(\n",
    "        lambda x: float(TextBlob(x).sentiment.polarity)\n",
    "    )\n",
    "    df[\"sentiment_subjectivity\"] = df[\"text\"].progress_apply(\n",
    "        lambda x: float(TextBlob(x).sentiment.subjectivity)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def process_text_file(filename: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(os.path.join(filename))\n",
    "    assert \"text\" in df.columns\n",
    "    df[\"text\"] = df[\"text\"].astype(str)\n",
    "    df[\"text_length\"] = df[\"text\"].str.len()\n",
    "    df[\"word_count\"] = df[\"text\"].str.split().str.len()\n",
    "    df[\"sentence_count\"] = df[\"text\"].str.count(r\"[.!?]+\").replace(0, 1)\n",
    "    df[\"avg_sentence_length\"] = (df[\"word_count\"] / df[\"sentence_count\"]).clip(\n",
    "        upper=100\n",
    "    )\n",
    "    df[\"punct_count\"] = df[\"text\"].str.count(r\"[^\\w\\s]\")\n",
    "    df[\"punct_ratio\"] = (df[\"punct_count\"] / df[\"text_length\"]).clip(0, 0.3)\n",
    "    df[\"ttr\"] = df[\"text\"].apply(_ttr)\n",
    "    df[\"digit_ratio\"] = df[\"text\"].str.count(r\"\\d\") / (\n",
    "        df[\"text_length\"].replace(0, 1)\n",
    "    )\n",
    "    df[\"upper_ratio\"] = df[\"text\"].str.count(r\"[A-Z]\") / (\n",
    "        df[\"text_length\"].replace(0, 1)\n",
    "    )\n",
    "    df[\"bangs\"] = df[\"text\"].str.count(r\"!\")\n",
    "    df[\"questions\"] = df[\"text\"].str.count(r\"\\?\")\n",
    "    return df\n",
    "\n",
    "\n",
    "log_step_end(\"Processing and features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24b3d62",
   "metadata": {},
   "source": [
    "## Binary features and 2^3 sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17276e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start(\"Binary features and 2^3 sweep\")\n",
    "\n",
    "\n",
    "def ends_with_letter(text: str) -> int:\n",
    "    s = text.rstrip()\n",
    "    return int(len(s) > 0 and s[-1] in string.ascii_letters)\n",
    "\n",
    "\n",
    "def has_5gram_repetition(text: str) -> int:\n",
    "    toks = re.findall(r\"\\S+\", text)\n",
    "    if len(toks) < 10:\n",
    "        return 0\n",
    "    seen = {}\n",
    "    w = 5\n",
    "    for i in range(len(toks) - w + 1):\n",
    "        key = tuple(toks[i : i + w])\n",
    "        if key in seen:\n",
    "            return 1\n",
    "        seen[key] = 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "COMMON_SMALL = set(\n",
    "    [\n",
    "        \"the\",\n",
    "        \"be\",\n",
    "        \"to\",\n",
    "        \"of\",\n",
    "        \"and\",\n",
    "        \"a\",\n",
    "        \"in\",\n",
    "        \"that\",\n",
    "        \"have\",\n",
    "        \"i\",\n",
    "        \"it\",\n",
    "        \"for\",\n",
    "        \"not\",\n",
    "        \"on\",\n",
    "        \"with\",\n",
    "        \"he\",\n",
    "        \"as\",\n",
    "        \"you\",\n",
    "        \"do\",\n",
    "        \"at\",\n",
    "        \"this\",\n",
    "        \"but\",\n",
    "        \"his\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def max_uncommon_binary(\n",
    "    text: str, thr_rep: int = 3, thr_count: int = 5\n",
    ") -> int:\n",
    "    toks = [t.lower() for t in re.findall(r\"\\w+\", text)]\n",
    "    if not toks:\n",
    "        return 0\n",
    "    freqs = {}\n",
    "    uncommon = 0\n",
    "    for t in toks:\n",
    "        if t not in COMMON_SMALL:\n",
    "            uncommon += 1\n",
    "            freqs[t] = freqs.get(t, 0) + 1\n",
    "    if uncommon < thr_count:\n",
    "        return 0\n",
    "    return int(any(v >= thr_rep for v in freqs.values()))\n",
    "\n",
    "\n",
    "def add_binary_feats(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    tqdm.pandas()\n",
    "    out[\"ends_with_letter\"] = out[\"text\"].progress_apply(ends_with_letter)\n",
    "    out[\"has_5gram_repetition\"] = out[\"text\"].progress_apply(\n",
    "        has_5gram_repetition\n",
    "    )\n",
    "    out[\"max_uncommon_binary\"] = out[\"text\"].progress_apply(\n",
    "        max_uncommon_binary\n",
    "    )\n",
    "    return out\n",
    "\n",
    "\n",
    "def sweep_binary_subsets(y_true: np.ndarray, fe_df: pd.DataFrame):\n",
    "    cols = [\"ends_with_letter\", \"has_5gram_repetition\", \"max_uncommon_binary\"]\n",
    "    best_f1, best_key = -1.0, \"none\"\n",
    "    for mask in range(1, 1 << len(cols)):\n",
    "        sel = [cols[i] for i in range(len(cols)) if (mask >> i) & 1]\n",
    "        rule = fe_df[sel].any(axis=1).astype(int).values\n",
    "        f1 = f1_score(y_true, rule)\n",
    "        key = \"|\".join(sel)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_key = f1, key\n",
    "    return best_key, float(best_f1)\n",
    "\n",
    "\n",
    "log_step_end(\"Binary features and 2^3 sweep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880cc586",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840e0887",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start(\"Load data\")\n",
    "\n",
    "from pathlib import Path\n",
    "import hashlib\n",
    "\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "if not (PROJECT_ROOT / DATA_DIR).exists():\n",
    "    for parent in PROJECT_ROOT.parents:\n",
    "        if (parent / DATA_DIR).exists():\n",
    "            PROJECT_ROOT = parent\n",
    "            break\n",
    "\n",
    "\n",
    "def resolve_path(path_str: str) -> str:\n",
    "    p = Path(path_str)\n",
    "    if p.is_absolute():\n",
    "        return str(p)\n",
    "    if p.parent == Path(\".\"):\n",
    "        data_dir = Path(DATA_DIR)\n",
    "        if not data_dir.is_absolute():\n",
    "            data_dir = PROJECT_ROOT / data_dir\n",
    "        candidate = data_dir / p.name\n",
    "        if candidate.exists():\n",
    "            return str(candidate)\n",
    "    return str((PROJECT_ROOT / p).resolve())\n",
    "\n",
    "\n",
    "# Reassemble chunked CSVs if needed\n",
    "def ensure_chunked_csv(path: Path) -> None:\n",
    "    if path.exists():\n",
    "        return\n",
    "    parts = sorted(path.parent.glob(path.name + \".part*\"))\n",
    "    if not parts:\n",
    "        raise FileNotFoundError(f\"Missing {path} and no chunk files found.\")\n",
    "    tmp_path = path.with_suffix(path.suffix + \".tmp\")\n",
    "    if tmp_path.exists():\n",
    "        tmp_path.unlink()\n",
    "    hasher = hashlib.sha256()\n",
    "    with tmp_path.open(\"wb\") as out:\n",
    "        for part in parts:\n",
    "            with part.open(\"rb\") as f:\n",
    "                while True:\n",
    "                    chunk = f.read(1024 * 1024)\n",
    "                    if not chunk:\n",
    "                        break\n",
    "                    out.write(chunk)\n",
    "                    hasher.update(chunk)\n",
    "    sha_path = path.with_suffix(path.suffix + \".sha256\")\n",
    "    if sha_path.exists():\n",
    "        expected = sha_path.read_text().split()[0]\n",
    "        actual = hasher.hexdigest()\n",
    "        if expected != actual:\n",
    "            tmp_path.unlink(missing_ok=True)\n",
    "            raise ValueError(\n",
    "                f\"SHA256 mismatch for {path}: expected {expected} got {actual}\"\n",
    "            )\n",
    "    tmp_path.replace(path)\n",
    "    log_step(f\"Reassembled {path} from {len(parts)} chunks.\")\n",
    "\n",
    "\n",
    "train_path = Path(resolve_path(TRAIN_CSV))\n",
    "val_path = Path(resolve_path(VAL_CSV))\n",
    "test_path = Path(resolve_path(TEST_CSV))\n",
    "ensure_chunked_csv(train_path)\n",
    "ensure_chunked_csv(val_path)\n",
    "ensure_chunked_csv(test_path)\n",
    "\n",
    "train = process_text_file(str(train_path))\n",
    "val = process_text_file(str(val_path))\n",
    "test = process_text_file(str(test_path))\n",
    "assert \"label\" in train.columns and \"label\" in val.columns\n",
    "assert \"label\" not in test.columns\n",
    "assert \"id\" in test.columns\n",
    "print(\"Rows:\", len(train), len(val), len(test))\n",
    "log_step_end(\"Load data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542007f6",
   "metadata": {},
   "source": [
    "## Sentiment + binaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d1ab0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start(\"Sentiment + binaries\")\n",
    "train = _sentiment(train)\n",
    "val = _sentiment(val)\n",
    "test = _sentiment(test)\n",
    "train = add_binary_feats(train)\n",
    "val = add_binary_feats(val)\n",
    "test = add_binary_feats(test)\n",
    "rk, rf1 = sweep_binary_subsets(val[\"label\"].astype(int).values, val)\n",
    "print(f\"Best binary subset (val): {rk} | F1={rf1:.4f}\")\n",
    "log_step_end(\"Sentiment + binaries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbb7f0d",
   "metadata": {},
   "source": [
    "## Numeric + TF\u2013IDF design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038226de",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start(\"Numeric + TF\u2013IDF design\")\n",
    "num_cols = [\n",
    "    \"text_length\",\n",
    "    \"word_count\",\n",
    "    \"ttr\",\n",
    "    \"sentence_count\",\n",
    "    \"avg_sentence_length\",\n",
    "    \"punct_ratio\",\n",
    "    \"sentiment_polarity\",\n",
    "    \"sentiment_subjectivity\",\n",
    "    \"digit_ratio\",\n",
    "    \"upper_ratio\",\n",
    "    \"bangs\",\n",
    "    \"questions\",\n",
    "    \"ends_with_letter\",\n",
    "    \"has_5gram_repetition\",\n",
    "    \"max_uncommon_binary\",\n",
    "]\n",
    "Xtr_num = csr_matrix(train[num_cols].to_numpy(dtype=np.float32))\n",
    "Xva_num = csr_matrix(val[num_cols].to_numpy(dtype=np.float32))\n",
    "Xte_num = csr_matrix(test[num_cols].to_numpy(dtype=np.float32))\n",
    "vec_word = TfidfVectorizer(\n",
    "    ngram_range=(1, 3),\n",
    "    max_features=50000,\n",
    "    min_df=2,\n",
    "    stop_words=\"english\",\n",
    "    dtype=np.float32,\n",
    ")\n",
    "Xtr_w = vec_word.fit_transform(train[\"text\"])\n",
    "Xva_w = vec_word.transform(val[\"text\"])\n",
    "Xte_w = vec_word.transform(test[\"text\"])\n",
    "X_train = hstack([Xtr_num, Xtr_w])\n",
    "X_val = hstack([Xva_num, Xva_w])\n",
    "X_test = hstack([Xte_num, Xte_w])\n",
    "y_train = train[\"label\"].astype(int).values\n",
    "y_val = val[\"label\"].astype(int).values\n",
    "print(\"Shapes:\", X_train.shape, X_val.shape, X_test.shape)\n",
    "_gc()\n",
    "log_step_end(\"Numeric + TF\u2013IDF design\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb16023",
   "metadata": {},
   "source": [
    "## Tuning and calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351b5ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start(\"Tuning and calibration\")\n",
    "\n",
    "\n",
    "def _xgb_space():\n",
    "    return {\n",
    "        \"n_estimators\": [200, 300, 400, 500],\n",
    "        \"max_depth\": [4, 6, 8],\n",
    "        \"learning_rate\": [0.05, 0.1],\n",
    "        \"min_child_weight\": [1, 3],\n",
    "        \"subsample\": [0.7, 1.0],\n",
    "        \"colsample_bytree\": [0.7, 1.0],\n",
    "        \"reg_alpha\": [0.0, 0.1, 0.5],\n",
    "        \"reg_lambda\": [0.5, 1.0, 1.5],\n",
    "    }\n",
    "\n",
    "\n",
    "def _lr_space():\n",
    "    return {\n",
    "        \"C\": [0.5, 1.0, 2.0, 4.0],\n",
    "        \"penalty\": [\"l2\"],\n",
    "        \"solver\": [\"liblinear\", \"lbfgs\"],\n",
    "        \"class_weight\": [None, \"balanced\"],\n",
    "    }\n",
    "\n",
    "\n",
    "def _search_signature(param_distributions, n_iter, kfolds, random_state, X_shape):\n",
    "    payload = {\n",
    "        \"param_distributions\": param_distributions,\n",
    "        \"n_iter\": n_iter,\n",
    "        \"kfolds\": kfolds,\n",
    "        \"random_state\": random_state,\n",
    "        \"X_shape\": list(X_shape),\n",
    "    }\n",
    "    raw = json.dumps(payload, sort_keys=True, default=str)\n",
    "    return hashlib.md5(raw.encode()).hexdigest()[:10]\n",
    "\n",
    "\n",
    "def _load_results(results_path: Path):\n",
    "    rows = []\n",
    "    if not results_path.exists():\n",
    "        return rows\n",
    "    with results_path.open() as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                rows.append(json.loads(line))\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "    return rows\n",
    "\n",
    "\n",
    "def _checkpointed_random_search(\n",
    "    estimator_factory,\n",
    "    param_distributions,\n",
    "    X,\n",
    "    y,\n",
    "    n_iter,\n",
    "    kfolds,\n",
    "    random_state,\n",
    "    search_name,\n",
    "):\n",
    "    ckpt_dir = Path(PROJECT_ROOT) / \"checkpoints\"\n",
    "    ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
    "    sig = _search_signature(\n",
    "        param_distributions, n_iter, kfolds, random_state, X.shape\n",
    "    )\n",
    "    candidates_path = ckpt_dir / f\"{search_name}_{sig}_candidates.json\"\n",
    "    results_path = ckpt_dir / f\"{search_name}_{sig}_results.jsonl\"\n",
    "    meta_path = ckpt_dir / f\"{search_name}_{sig}_meta.json\"\n",
    "\n",
    "    if candidates_path.exists():\n",
    "        candidates = json.loads(candidates_path.read_text())\n",
    "    else:\n",
    "        candidates = list(\n",
    "            ParameterSampler(\n",
    "                param_distributions, n_iter=n_iter, random_state=random_state\n",
    "            )\n",
    "        )\n",
    "        candidates_path.write_text(json.dumps(candidates, indent=2))\n",
    "\n",
    "    meta_path.write_text(\n",
    "        json.dumps(\n",
    "            {\n",
    "                \"signature\": sig,\n",
    "                \"n_iter\": n_iter,\n",
    "                \"kfolds\": kfolds,\n",
    "                \"random_state\": random_state,\n",
    "                \"X_shape\": list(X.shape),\n",
    "                \"n_candidates\": len(candidates),\n",
    "            },\n",
    "            indent=2,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    rows = _load_results(results_path)\n",
    "    scores_by_cand = {}\n",
    "    done = set()\n",
    "    for row in rows:\n",
    "        cand = row.get(\"cand_idx\")\n",
    "        fold = row.get(\"fold_idx\")\n",
    "        status = row.get(\"status\")\n",
    "        if cand is None or fold is None:\n",
    "            continue\n",
    "        cand = int(cand)\n",
    "        fold = int(fold)\n",
    "        if status == \"ok\":\n",
    "            scores_by_cand.setdefault(cand, {})[fold] = float(\n",
    "                row.get(\"score\", 0.0)\n",
    "            )\n",
    "        if status in (\"ok\", \"fail\"):\n",
    "            done.add((cand, fold))\n",
    "\n",
    "    completed = sum(\n",
    "        1 for scores in scores_by_cand.values() if len(scores) == kfolds\n",
    "    )\n",
    "    if rows:\n",
    "        print(\n",
    "            f\"Resuming {search_name}: {completed}/{len(candidates)} \"\n",
    "            \"candidates fully scored.\"\n",
    "        )\n",
    "\n",
    "    splits = list(\n",
    "        StratifiedKFold(\n",
    "            n_splits=kfolds, shuffle=True, random_state=random_state\n",
    "        ).split(X, y)\n",
    "    )\n",
    "\n",
    "    best_score = -1.0\n",
    "    best_params = None\n",
    "    for cand_idx, scores in scores_by_cand.items():\n",
    "        if len(scores) == kfolds:\n",
    "            mean = float(np.mean(list(scores.values())))\n",
    "            if mean > best_score:\n",
    "                best_score = mean\n",
    "                best_params = candidates[cand_idx]\n",
    "\n",
    "    with results_path.open(\"a\") as f:\n",
    "        for cand_idx, params in enumerate(candidates):\n",
    "            cand_scores = scores_by_cand.setdefault(cand_idx, {})\n",
    "            if len(cand_scores) == kfolds:\n",
    "                continue\n",
    "            log_step(\n",
    "                f\"{search_name}: candidate {cand_idx + 1}/{len(candidates)}\"\n",
    "            )\n",
    "            for fold_idx, (tr_idx, va_idx) in enumerate(splits):\n",
    "                if (cand_idx, fold_idx) in done:\n",
    "                    continue\n",
    "                start = time.perf_counter()\n",
    "                status = \"ok\"\n",
    "                score = None\n",
    "                error = None\n",
    "                try:\n",
    "                    model = estimator_factory(params)\n",
    "                    model.fit(X[tr_idx], y[tr_idx])\n",
    "                    preds = model.predict(X[va_idx])\n",
    "                    score = float(f1_score(y[va_idx], preds))\n",
    "                    cand_scores[fold_idx] = score\n",
    "                except Exception as exc:\n",
    "                    status = \"fail\"\n",
    "                    error = str(exc)\n",
    "                elapsed = time.perf_counter() - start\n",
    "                record = {\n",
    "                    \"cand_idx\": cand_idx,\n",
    "                    \"fold_idx\": fold_idx,\n",
    "                    \"status\": status,\n",
    "                    \"score\": score,\n",
    "                    \"elapsed_sec\": round(elapsed, 2),\n",
    "                    \"params\": params,\n",
    "                    \"error\": error,\n",
    "                }\n",
    "                f.write(json.dumps(record) + \"\n",
    "\")\n",
    "                f.flush()\n",
    "                os.fsync(f.fileno())\n",
    "                done.add((cand_idx, fold_idx))\n",
    "                if status == \"ok\":\n",
    "                    log_step(\n",
    "                        f\"{search_name} cand {cand_idx + 1} \"\n",
    "                        f\"fold {fold_idx + 1}/{kfolds} f1={score:.4f} \"\n",
    "                        f\"({elapsed / 60:.1f} min)\"\n",
    "                    )\n",
    "                else:\n",
    "                    log_step(\n",
    "                        f\"{search_name} cand {cand_idx + 1} \"\n",
    "                        f\"fold {fold_idx + 1}/{kfolds} failed: {error}\"\n",
    "                    )\n",
    "                _gc()\n",
    "            if len(cand_scores) == kfolds:\n",
    "                mean = float(np.mean(list(cand_scores.values())))\n",
    "                log_step(\n",
    "                    f\"{search_name} candidate {cand_idx + 1} mean f1={mean:.4f}\"\n",
    "                )\n",
    "                if mean > best_score:\n",
    "                    best_score = mean\n",
    "                    best_params = params\n",
    "\n",
    "    if best_params is None:\n",
    "        return None\n",
    "\n",
    "    params_path = ckpt_dir / f\"{search_name}_{sig}_best.json\"\n",
    "    params_path.write_text(\n",
    "        json.dumps(\n",
    "            {\"best_score\": best_score, \"best_params\": best_params}, indent=2\n",
    "        )\n",
    "    )\n",
    "    return best_params\n",
    "\n",
    "\n",
    "def tune_xgb(X, y):\n",
    "    base_params = {\n",
    "        \"random_state\": 42,\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"max_bin\": 256,\n",
    "        \"n_jobs\": 1,\n",
    "    }\n",
    "    log_step_start(\"XGB randomized search\")\n",
    "    best_params = _checkpointed_random_search(\n",
    "        lambda p: XGBClassifier(**base_params, **p),\n",
    "        _xgb_space(),\n",
    "        X,\n",
    "        y,\n",
    "        n_iter=CFG.xgb_iter,\n",
    "        kfolds=CFG.kfolds,\n",
    "        random_state=42,\n",
    "        search_name=\"xgb_search\",\n",
    "    )\n",
    "    log_step_end(\"XGB randomized search\")\n",
    "    if best_params is None:\n",
    "        warnings.warn(\"XGB search produced no valid candidates; using default.\")\n",
    "        model = XGBClassifier(**base_params)\n",
    "        model.fit(X, y)\n",
    "        return model\n",
    "    model = XGBClassifier(**base_params, **best_params)\n",
    "    log_step_start(\"XGB refit on full data\")\n",
    "    model.fit(X, y)\n",
    "    log_step_end(\"XGB refit on full data\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def tune_lr(X, y):\n",
    "    base_params = {\n",
    "        \"max_iter\": 2000,\n",
    "        \"random_state\": 42,\n",
    "    }\n",
    "    log_step_start(\"LR randomized search\")\n",
    "    best_params = _checkpointed_random_search(\n",
    "        lambda p: LogisticRegression(**base_params, **p),\n",
    "        _lr_space(),\n",
    "        X,\n",
    "        y,\n",
    "        n_iter=CFG.lr_iter,\n",
    "        kfolds=CFG.kfolds,\n",
    "        random_state=42,\n",
    "        search_name=\"lr_search\",\n",
    "    )\n",
    "    log_step_end(\"LR randomized search\")\n",
    "    if best_params is None:\n",
    "        warnings.warn(\"LR search produced no valid candidates; using default.\")\n",
    "        model = LogisticRegression(**base_params)\n",
    "        model.fit(X, y)\n",
    "        return model\n",
    "    model = LogisticRegression(**base_params, **best_params)\n",
    "    log_step_start(\"LR refit on full data\")\n",
    "    model.fit(X, y)\n",
    "    log_step_end(\"LR refit on full data\")\n",
    "    return model\n",
    "\n",
    "\n",
    "xgb_tuned = tune_xgb(X_train, y_train)\n",
    "lr_tuned = tune_lr(X_train, y_train)\n",
    "X_trval = vstack([X_train, X_val])\n",
    "y_trval = np.concatenate([y_train, y_val])\n",
    "log_step_start(\"Fold 1/1 (single split)\")\n",
    "log_step_start(\"XGB training epochs\")\n",
    "xgb_tuned.fit(\n",
    "    X_trval,\n",
    "    y_trval,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=True,\n",
    "    callbacks=[EarlyStopping(rounds=50)],\n",
    ")\n",
    "log_step_end(\"XGB training epochs\")\n",
    "log_step_start(\"LR fit\")\n",
    "lr_tuned.fit(X_trval, y_trval)\n",
    "log_step_end(\"LR fit\")\n",
    "log_step_end(\"Fold 1/1 (single split)\")\n",
    "\n",
    "cal_xgb = CalibratedClassifierCV(xgb_tuned, method=\"sigmoid\", cv=\"prefit\")\n",
    "cal_xgb.fit(X_val, y_val)\n",
    "cal_lr = CalibratedClassifierCV(lr_tuned, method=\"sigmoid\", cv=\"prefit\")\n",
    "cal_lr.fit(X_val, y_val)\n",
    "_gc()\n",
    "log_step_end(\"Tuning and calibration\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9c0101",
   "metadata": {},
   "source": [
    "## Ensembling, thresholding, prevalence match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b81022",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start(\"Ensembling, thresholding, prevalence match\")\n",
    "\n",
    "\n",
    "def decode_prevalence(y_prob: np.ndarray, pos_rate: float) -> np.ndarray:\n",
    "    n = len(y_prob)\n",
    "    k = int(round(pos_rate * n))\n",
    "    idx = np.argsort(-y_prob)\n",
    "    out = np.zeros(n, dtype=int)\n",
    "    out[idx[:k]] = 1\n",
    "    return out\n",
    "\n",
    "\n",
    "p_xgb = cal_xgb.predict_proba(X_val)[:, 1]\n",
    "p_lr = cal_lr.predict_proba(X_val)[:, 1]\n",
    "best_w, best_f1, best_thr = 0.5, -1.0, 0.5\n",
    "for w in np.linspace(0.0, 1.0, 21):\n",
    "    p = w * p_xgb + (1.0 - w) * p_lr\n",
    "    for thr in np.arange(0.1, 0.91, 0.01):\n",
    "        f1 = f1_score(y_val, (p >= thr).astype(int))\n",
    "        if f1 > best_f1:\n",
    "            best_w, best_f1, best_thr = float(w), float(f1), float(thr)\n",
    "print(f\"Threshold head: w={best_w:.2f} thr={best_thr:.2f} F1={best_f1:.4f}\")\n",
    "p_ens = best_w * p_xgb + (1.0 - best_w) * p_lr\n",
    "val_pos_rate = float(np.mean(y_val))\n",
    "yhat_topk = decode_prevalence(p_ens, val_pos_rate)\n",
    "f1_topk = f1_score(y_val, yhat_topk)\n",
    "print(f\"Prevalence head: rate={val_pos_rate:.3f} F1={f1_topk:.4f}\")\n",
    "rk, rf1 = sweep_binary_subsets(y_val, val)\n",
    "print(f\"Rule head (best subset {rk}) F1={rf1:.4f}\")\n",
    "heads = [(\"threshold\", best_f1), (\"prevalence\", f1_topk), (\"rule\", rf1)]\n",
    "heads.sort(key=lambda x: x[1], reverse=True)\n",
    "print(\"Head ranking:\", heads)\n",
    "log_step_end(\"Ensembling, thresholding, prevalence match\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6d5fd4",
   "metadata": {},
   "source": [
    "## Validation diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cb11f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start(\"Validation diagnostics\")\n",
    "winner = heads[0][0]\n",
    "if winner == \"threshold\":\n",
    "    yhat_val = (p_ens >= best_thr).astype(int)\n",
    "elif winner == \"prevalence\":\n",
    "    yhat_val = yhat_topk\n",
    "else:\n",
    "    yhat_val = (\n",
    "        val[\n",
    "            [\"ends_with_letter\", \"has_5gram_repetition\", \"max_uncommon_binary\"]\n",
    "        ]\n",
    "        .any(axis=1)\n",
    "        .astype(int)\n",
    "        .values\n",
    "    )\n",
    "print(classification_report(y_val, yhat_val))\n",
    "residual_plot(y_val, p_ens, \"Residuals: ensemble on val\")\n",
    "qq_plot(y_val - p_ens, \"QQ: residuals (val)\")\n",
    "plot_roc_pr(y_val, p_ens, \"Validation ROC/PR (ensemble)\")\n",
    "plot_confusion(y_val, yhat_val, \"Confusion (val, winner head)\")\n",
    "log_step_end(\"Validation diagnostics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf55f5f2",
   "metadata": {},
   "source": [
    "## Predict test and save submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2815fb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start(\"Predict test and save submission\")\n",
    "p_xgb_te = predict_proba_chunks(cal_xgb, X_test)\n",
    "p_lr_te = predict_proba_chunks(cal_lr, X_test)\n",
    "p_ens_te = best_w * p_xgb_te + (1.0 - best_w) * p_lr_te\n",
    "if winner == \"threshold\":\n",
    "    yhat_te = (p_ens_te >= best_thr).astype(int)\n",
    "elif winner == \"prevalence\":\n",
    "    yhat_te = decode_prevalence(p_ens_te, val_pos_rate)\n",
    "else:\n",
    "    yhat_te = (\n",
    "        test[\n",
    "            [\"ends_with_letter\", \"has_5gram_repetition\", \"max_uncommon_binary\"]\n",
    "        ]\n",
    "        .any(axis=1)\n",
    "        .astype(int)\n",
    "        .values\n",
    "    )\n",
    "submission = pd.DataFrame({\"id\": test[\"id\"], \"label\": yhat_te})\n",
    "outputs_dir = \"outputs\"\n",
    "os.makedirs(outputs_dir, exist_ok=True)\n",
    "submission_path = os.path.join(outputs_dir, \"submission_hvsm_prod_2.csv\")\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(\"Saved\", submission_path, \"with\", len(submission), \"rows\")\n",
    "_gc()\n",
    "log_step_end(\"Predict test and save submission\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
