{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f90190d50204568b1feaa2801c7ed61",
   "metadata": {},
   "source": [
    "# HVSM Notebook: hvsm_prod.ipynb\n",
    "\n",
    "- Runs with: slurm_scripts/hvsm_job.sh\n",
    "- Purpose: Baseline CPU TF-IDF + XGBoost + Logistic Regression pipeline.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abe8c5cd387471d933adf278f08b735",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters (papermill)\n",
    "DATA_DIR = \"data\"\n",
    "TRAIN_CSV = \"data/train.csv\"\n",
    "VAL_CSV = \"data/val.csv\"\n",
    "TEST_CSV = \"data/test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16df9532",
   "metadata": {},
   "source": [
    "# Kaggle Baseline: TF\u2013IDF + XGBoost + Logistic Regression\n\nThis notebook implements the exact baseline pipeline you provided, with documentation, type hints, assertions, and diagnostic plots. It expects `data/train.csv`, `data/val.csv`, and `data/test.csv` to reside in `data/`. The outputs include validation reports and a `outputs/submission_hvsm_prod.csv` file for Kaggle.\n\nThe workflow:\n1. Load CSVs and engineer basic text features.\n2. Compute TF\u2013IDF up to trigrams.\n3. Train XGBoost and Logistic Regression models.\n4. Calibrate via Platt scaling.\n5. Ensemble (weighted average) and threshold tune on validation.\n6. Generate predictions on `data/test.csv`.\n\nAdditional diagnostics: QQ plot, residual plot, violin plot, and a brief sanity audit of the inputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40d1a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from typing import List, Tuple\n",
    "import os\n",
    "import re\n",
    "import inspect\n",
    "import warnings\n",
    "import gc\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "try:\n",
    "    import seaborn as sns  # optional, for violin plots\n",
    "except Exception:  # pragma: no cover\n",
    "    sns = None\n",
    "\n",
    "try:\n",
    "    from textblob import TextBlob\n",
    "except Exception as e:  # pragma: no cover\n",
    "    TextBlob = None\n",
    "    warnings.warn(\"TextBlob not available; sentiment features will be zeros.\")\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129a7035",
   "metadata": {},
   "source": [
    "## Utilities and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc92b91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gc() -> None:\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "_STEP_STARTS = {}\n",
    "\n",
    "\n",
    "def log_step(msg: str) -> None:\n",
    "    ts = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"[{ts}] {msg}\", flush=True)\n",
    "\n",
    "\n",
    "def log_step_start(name: str) -> None:\n",
    "    _STEP_STARTS[name] = time.perf_counter()\n",
    "    log_step(f\"START: {name}\")\n",
    "\n",
    "\n",
    "def log_step_end(name: str) -> None:\n",
    "    start = _STEP_STARTS.pop(name, None)\n",
    "    if start is None:\n",
    "        log_step(f\"END: {name}\")\n",
    "    else:\n",
    "        elapsed = time.perf_counter() - start\n",
    "        log_step(f\"END: {name} (elapsed {elapsed:.1f}s)\")\n",
    "\n",
    "\n",
    "def predict_proba_chunks(model, X, chunk_size: int = 50000) -> np.ndarray:\n",
    "    n = X.shape[0]\n",
    "    out = np.empty(n, dtype=np.float32)\n",
    "    for start in range(0, n, chunk_size):\n",
    "        end = min(start + chunk_size, n)\n",
    "        out[start:end] = model.predict_proba(X[start:end])[:, 1]\n",
    "    return out\n",
    "\n",
    "\n",
    "def qq_plot(residuals: np.ndarray, title: str) -> None:\n",
    "    \"\"\"Draw a QQ plot of residuals.\n",
    "\n",
    "    Args:\n",
    "        residuals: Array of residuals.\n",
    "        title: Plot title.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def residual_plot(y_true: np.ndarray, y_prob: np.ndarray, title: str) -> None:\n",
    "    \"\"\"Scatter residuals vs predicted probabilities.\n",
    "\n",
    "    Args:\n",
    "        y_true: True binary labels.\n",
    "        y_prob: Predicted probabilities for the positive class.\n",
    "        title: Plot title.\n",
    "    \"\"\"\n",
    "    resid = y_true - y_prob\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.scatter(y_prob, resid, s=8)\n",
    "    plt.axhline(0.0, linestyle=\"--\")\n",
    "    plt.xlabel(\"p(y=1)\")\n",
    "    plt.ylabel(\"residual\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def violin_by_label(\n",
    "    df: pd.DataFrame, label_col: str, feat_col: str, title: str\n",
    ") -> None:\n",
    "    \"\"\"Violin plot of a numeric feature split by label.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame containing labels and the feature.\n",
    "        label_col: Name of the label column.\n",
    "        feat_col: Name of the numeric feature column.\n",
    "        title: Plot title.\n",
    "    \"\"\"\n",
    "    if sns is None:  # fallback to simple boxplot if seaborn missing\n",
    "        plt.figure(figsize=(5, 4))\n",
    "        df.boxplot(column=feat_col, by=label_col)\n",
    "        plt.title(title)\n",
    "        plt.suptitle(\"\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        return\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.violinplot(data=df, x=label_col, y=feat_col)\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e300b63",
   "metadata": {},
   "source": [
    "## Data loading and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8cd811",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start(\"Data loading and processing\")\n",
    "\n",
    "\n",
    "def process_text_file(filename: str) -> pd.DataFrame:\n",
    "    \"\"\"Load CSV and compute simple text-derived features.\n",
    "\n",
    "    The file is expected to contain at least a `text` column, and, for\n",
    "    training/validation, a `label` column.\n",
    "\n",
    "    Args:\n",
    "        filename: CSV path relative to the notebook directory.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with additional feature columns.\n",
    "\n",
    "    Raises:\n",
    "        AssertionError: If required columns are missing.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(os.path.join(filename))\n",
    "    assert \"text\" in df.columns, \"CSV must contain a text column.\"\n",
    "    df[\"text\"] = df[\"text\"].astype(str)\n",
    "\n",
    "    df[\"text_length\"] = df[\"text\"].str.len()\n",
    "    df[\"word_count\"] = df[\"text\"].str.split().str.len()\n",
    "    df[\"sentence_count\"] = df[\"text\"].str.count(r\"[.!?]+\").replace(0, 1)\n",
    "    df[\"avg_sentence_length\"] = (df[\"word_count\"] / df[\"sentence_count\"]).clip(\n",
    "        upper=100\n",
    "    )\n",
    "    df[\"punct_count\"] = df[\"text\"].str.count(r\"[^\\w\\s]\")\n",
    "    df[\"punct_ratio\"] = (df[\"punct_count\"] / df[\"text_length\"]).clip(0, 0.3)\n",
    "\n",
    "    def ttr(text: str) -> float:\n",
    "        words = re.findall(r\"\\S+\", text.lower())\n",
    "        return len(set(words)) / len(words) if len(words) > 0 else 0.0\n",
    "\n",
    "    tqdm.pandas()\n",
    "    df[\"ttr\"] = df[\"text\"].progress_apply(ttr)\n",
    "    return df\n",
    "\n",
    "\n",
    "log_step_end(\"Data loading and processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a44474c",
   "metadata": {},
   "source": [
    "## TF\u2013IDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61f992e",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start(\"TF\u2013IDF features\")\n",
    "\n",
    "\n",
    "def add_ngram_tfidf(\n",
    "    train_texts: pd.Series,\n",
    "    valid_texts: pd.Series,\n",
    "    test_texts: pd.Series,\n",
    "    n: int = 11,\n",
    "    max_features: int = 5000,\n",
    ") -> Tuple[csr_matrix, csr_matrix, csr_matrix]:\n",
    "    \"\"\"Build an n-gram TF\u2013IDF representation.\n",
    "\n",
    "    Args:\n",
    "        train_texts: Training texts.\n",
    "        valid_texts: Validation texts.\n",
    "        test_texts: Test texts.\n",
    "        n: Maximum n-gram size.\n",
    "        max_features: Vocabulary size cap.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of sparse matrices (train, valid, test).\n",
    "    \"\"\"\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        ngram_range=(1, n),\n",
    "        max_features=max_features,\n",
    "        stop_words=\"english\",\n",
    "        dtype=np.float32,\n",
    "    )\n",
    "    X_train_ng = vectorizer.fit_transform(train_texts)\n",
    "    X_valid_ng = vectorizer.transform(valid_texts)\n",
    "    X_test_ng = vectorizer.transform(test_texts)\n",
    "    return X_train_ng, X_valid_ng, X_test_ng\n",
    "\n",
    "\n",
    "log_step_end(\"TF\u2013IDF features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518732dd",
   "metadata": {},
   "source": [
    "## Sentiment features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9898a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start(\"Sentiment features\")\n",
    "\n",
    "\n",
    "def add_sentiment_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Attach TextBlob sentiment features.\n",
    "\n",
    "    If TextBlob is unavailable, the features are set to zeros with a\n",
    "    warning.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with `text` column.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with `sentiment_polarity` and `sentiment_subjectivity`.\n",
    "    \"\"\"\n",
    "    tqdm.pandas()\n",
    "    if TextBlob is None:\n",
    "        df[\"sentiment_polarity\"] = 0.0\n",
    "        df[\"sentiment_subjectivity\"] = 0.0\n",
    "        return df\n",
    "\n",
    "    def _pol(x: str) -> float:\n",
    "        return float(TextBlob(x).sentiment.polarity)\n",
    "\n",
    "    def _subj(x: str) -> float:\n",
    "        return float(TextBlob(x).sentiment.subjectivity)\n",
    "\n",
    "    df[\"sentiment_polarity\"] = df[\"text\"].progress_apply(_pol)\n",
    "    df[\"sentiment_subjectivity\"] = df[\"text\"].progress_apply(_subj)\n",
    "    return df\n",
    "\n",
    "\n",
    "log_step_end(\"Sentiment features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7beafe4",
   "metadata": {},
   "source": [
    "## Load data (train/val/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2e3fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start(\"Load data (train/val/test)\")\n",
    "\n",
    "from pathlib import Path\n",
    "import hashlib\n",
    "\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "if not (PROJECT_ROOT / DATA_DIR).exists():\n",
    "    for parent in PROJECT_ROOT.parents:\n",
    "        if (parent / DATA_DIR).exists():\n",
    "            PROJECT_ROOT = parent\n",
    "            break\n",
    "\n",
    "\n",
    "def resolve_path(path_str: str) -> str:\n",
    "    p = Path(path_str)\n",
    "    if p.is_absolute():\n",
    "        return str(p)\n",
    "    if p.parent == Path(\".\"):\n",
    "        data_dir = Path(DATA_DIR)\n",
    "        if not data_dir.is_absolute():\n",
    "            data_dir = PROJECT_ROOT / data_dir\n",
    "        candidate = data_dir / p.name\n",
    "        if candidate.exists():\n",
    "            return str(candidate)\n",
    "    return str((PROJECT_ROOT / p).resolve())\n",
    "\n",
    "\n",
    "# Reassemble chunked CSVs if needed\n",
    "def ensure_chunked_csv(path: Path) -> None:\n",
    "    if path.exists():\n",
    "        return\n",
    "    parts = sorted(path.parent.glob(path.name + \".part*\"))\n",
    "    if not parts:\n",
    "        raise FileNotFoundError(f\"Missing {path} and no chunk files found.\")\n",
    "    tmp_path = path.with_suffix(path.suffix + \".tmp\")\n",
    "    if tmp_path.exists():\n",
    "        tmp_path.unlink()\n",
    "    hasher = hashlib.sha256()\n",
    "    with tmp_path.open(\"wb\") as out:\n",
    "        for part in parts:\n",
    "            with part.open(\"rb\") as f:\n",
    "                while True:\n",
    "                    chunk = f.read(1024 * 1024)\n",
    "                    if not chunk:\n",
    "                        break\n",
    "                    out.write(chunk)\n",
    "                    hasher.update(chunk)\n",
    "    sha_path = path.with_suffix(path.suffix + \".sha256\")\n",
    "    if sha_path.exists():\n",
    "        expected = sha_path.read_text().split()[0]\n",
    "        actual = hasher.hexdigest()\n",
    "        if expected != actual:\n",
    "            tmp_path.unlink(missing_ok=True)\n",
    "            raise ValueError(\n",
    "                f\"SHA256 mismatch for {path}: expected {expected} got {actual}\"\n",
    "            )\n",
    "    tmp_path.replace(path)\n",
    "    log_step(f\"Reassembled {path} from {len(parts)} chunks.\")\n",
    "\n",
    "\n",
    "# Strict file names in the `data/` folder\n",
    "train_path = Path(resolve_path(TRAIN_CSV))\n",
    "val_path = Path(resolve_path(VAL_CSV))\n",
    "test_path = Path(resolve_path(TEST_CSV))\n",
    "ensure_chunked_csv(train_path)\n",
    "ensure_chunked_csv(val_path)\n",
    "ensure_chunked_csv(test_path)\n",
    "\n",
    "train = process_text_file(str(train_path))\n",
    "validation = process_text_file(str(val_path))\n",
    "test = process_text_file(str(test_path))\n",
    "\n",
    "# Basic schema checks\n",
    "for name, df in [(\"train\", train), (\"val\", validation), (\"test\", test)]:\n",
    "    assert \"text\" in df.columns, f\"{name} missing 'text' column\"\n",
    "assert \"label\" in train.columns, \"train must have label\"\n",
    "assert \"label\" in validation.columns, \"val must have label\"\n",
    "assert \"label\" not in test.columns, \"test must NOT have label\"\n",
    "\n",
    "print(\"Rows: train\", len(train), \" val\", len(validation), \" test\", len(test))\n",
    "log_step_end(\"Load data (train/val/test)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3be7880",
   "metadata": {},
   "source": [
    "## Add sentiment features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b45dc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start(\"Add sentiment features\")\n",
    "train = add_sentiment_features(train)\n",
    "validation = add_sentiment_features(validation)\n",
    "test = add_sentiment_features(test)\n",
    "log_step_end(\"Add sentiment features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a210fd8",
   "metadata": {},
   "source": [
    "## Assemble features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09f0bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start(\"Assemble features\")\n",
    "feature_cols: List[str] = [\n",
    "    \"text_length\",\n",
    "    \"word_count\",\n",
    "    \"ttr\",\n",
    "    \"sentence_count\",\n",
    "    \"avg_sentence_length\",\n",
    "    \"punct_ratio\",\n",
    "    \"sentiment_polarity\",\n",
    "    \"sentiment_subjectivity\",\n",
    "]\n",
    "\n",
    "X_train_basic = train[feature_cols]\n",
    "X_valid_basic = validation[feature_cols]\n",
    "X_test_basic = test[feature_cols]\n",
    "\n",
    "X_train_ngram, X_valid_ngram, X_test_ngram = add_ngram_tfidf(\n",
    "    train[\"text\"], validation[\"text\"], test[\"text\"], n=11, max_features=5000\n",
    ")\n",
    "\n",
    "X_train = hstack(\n",
    "    [csr_matrix(X_train_basic.to_numpy(dtype=np.float32)), X_train_ngram]\n",
    ")\n",
    "X_valid = hstack(\n",
    "    [csr_matrix(X_valid_basic.to_numpy(dtype=np.float32)), X_valid_ngram]\n",
    ")\n",
    "X_test = hstack(\n",
    "    [csr_matrix(X_test_basic.to_numpy(dtype=np.float32)), X_test_ngram]\n",
    ")\n",
    "\n",
    "y_train = train[\"label\"]\n",
    "y_valid = validation[\"label\"]\n",
    "\n",
    "print(\"Shapes:\")\n",
    "print(\"  X_train:\", X_train.shape)\n",
    "print(\"  X_valid:\", X_valid.shape)\n",
    "print(\"  X_test :\", X_test.shape)\n",
    "_gc()\n",
    "log_step_end(\"Assemble features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782fc490",
   "metadata": {},
   "source": [
    "## Class balance and scale_pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c0dca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start(\"Class balance and scale_pos_weight\")\n",
    "counter = Counter(y_train)\n",
    "assert 0 in counter and 1 in counter, \"labels must be binary {0,1}\"\n",
    "scale_pos_weight = counter[0] / counter[1]\n",
    "print(\"Class counts:\", counter)\n",
    "print(\"scale_pos_weight:\", scale_pos_weight)\n",
    "log_step_end(\"Class balance and scale_pos_weight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce76837d",
   "metadata": {},
   "source": [
    "## Train XGBoost and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a75d9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start(\"Train XGBoost and Logistic Regression\")\n",
    "\n",
    "import json\n",
    "import hashlib\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "ckpt_root = Path(PROJECT_ROOT) if \"PROJECT_ROOT\" in globals() else Path.cwd()\n",
    "ckpt_dir = ckpt_root / \"checkpoints\"\n",
    "ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def _model_signature(name, params, X_shape, y_shape):\n",
    "    payload = {\n",
    "        \"name\": name,\n",
    "        \"params\": params,\n",
    "        \"X_shape\": list(X_shape),\n",
    "        \"y_shape\": list(y_shape),\n",
    "    }\n",
    "    raw = json.dumps(payload, sort_keys=True, default=str)\n",
    "    return hashlib.md5(raw.encode()).hexdigest()[:10]\n",
    "\n",
    "\n",
    "xgb_params = {\n",
    "    \"n_estimators\": 500,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"max_depth\": 6,\n",
    "    \"random_state\": 42,\n",
    "    \"eval_metric\": \"logloss\",\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"max_bin\": 256,\n",
    "    \"n_jobs\": 1,\n",
    "    \"scale_pos_weight\": scale_pos_weight,\n",
    "}\n",
    "\n",
    "es_rounds = 50\n",
    "total_rounds = xgb_params[\"n_estimators\"]\n",
    "chunk_rounds = 20\n",
    "\n",
    "xgb_sig = _model_signature(\"xgb\", xgb_params, X_train.shape, y_train.shape)\n",
    "ckpt_prefix = f\"hvsm_prod_xgb_{xgb_sig}_iter\"\n",
    "legacy_ckpt = ckpt_dir / f\"hvsm_prod_xgb_{xgb_sig}.joblib\"\n",
    "\n",
    "log_step(f\"XGB checkpoints dir: {ckpt_dir}\")\n",
    "log_step(\n",
    "    f\"XGB checkpoint prefix: {ckpt_prefix} \"\n",
    "    f\"(chunk={chunk_rounds}, total={total_rounds})\"\n",
    ")\n",
    "\n",
    "\n",
    "def _ckpt_path(rounds: int) -> Path:\n",
    "    return ckpt_dir / f\"{ckpt_prefix}{rounds:04d}.joblib\"\n",
    "\n",
    "\n",
    "def _latest_ckpt():\n",
    "    candidates = list(ckpt_dir.glob(f\"{ckpt_prefix}*.joblib\"))\n",
    "    if not candidates:\n",
    "        return None, 0\n",
    "    def _rounds(p: Path) -> int:\n",
    "        name = p.stem\n",
    "        try:\n",
    "            return int(name.rsplit(\"iter\", 1)[-1])\n",
    "        except Exception:\n",
    "            return 0\n",
    "    best = max(candidates, key=_rounds)\n",
    "    return best, _rounds(best)\n",
    "\n",
    "\n",
    "log_step_start(\"Fold 1/1 (single split)\")\n",
    "log_step_start(\"XGB training epochs\")\n",
    "\n",
    "ckpt_path, current_round = _latest_ckpt()\n",
    "if ckpt_path is not None:\n",
    "    xgb = joblib.load(ckpt_path)\n",
    "    log_step(f\"Loaded XGB checkpoint: {ckpt_path}\")\n",
    "elif legacy_ckpt.exists():\n",
    "    xgb = joblib.load(legacy_ckpt)\n",
    "    current_round = xgb.get_booster().num_boosted_rounds()\n",
    "    log_step(f\"Loaded legacy XGB checkpoint: {legacy_ckpt}\")\n",
    "else:\n",
    "    xgb = XGBClassifier(**xgb_params)\n",
    "\n",
    "fit_kwargs = {\"eval_set\": [(X_valid, y_valid)], \"verbose\": True}\n",
    "fit_sig = inspect.signature(xgb.fit)\n",
    "if \"early_stopping_rounds\" in fit_sig.parameters:\n",
    "    fit_kwargs[\"early_stopping_rounds\"] = es_rounds\n",
    "else:\n",
    "    warnings.warn(\n",
    "        \"XGBClassifier.fit does not support early_stopping_rounds; \"\n",
    "        \"running without it.\"\n",
    "    )\n",
    "\n",
    "while current_round < total_rounds:\n",
    "    rounds_to_add = min(chunk_rounds, total_rounds - current_round)\n",
    "    xgb.set_params(n_estimators=rounds_to_add)\n",
    "    xgb_model = xgb.get_booster() if current_round > 0 else None\n",
    "    xgb.fit(X_train, y_train, xgb_model=xgb_model, **fit_kwargs)\n",
    "    new_rounds = xgb.get_booster().num_boosted_rounds()\n",
    "    if new_rounds <= current_round:\n",
    "        warnings.warn(\"XGBoost made no progress in this chunk; stopping.\")\n",
    "        break\n",
    "    current_round = new_rounds\n",
    "    ckpt_path = _ckpt_path(current_round)\n",
    "    joblib.dump(xgb, ckpt_path)\n",
    "    log_step(f\"Saved XGB checkpoint: {ckpt_path}\")\n",
    "\n",
    "log_step_end(\"XGB training epochs\")\n",
    "\n",
    "lr_params = {\"max_iter\": 1000, \"random_state\": 42}\n",
    "\n",
    "lr_sig = _model_signature(\"lr\", lr_params, X_train.shape, y_train.shape)\n",
    "lr_ckpt = ckpt_dir / f\"hvsm_prod_lr_{lr_sig}.joblib\"\n",
    "\n",
    "log_step_start(\"LR fit\")\n",
    "if lr_ckpt.exists():\n",
    "    lr = joblib.load(lr_ckpt)\n",
    "    log_step(f\"Loaded LR checkpoint: {lr_ckpt}\")\n",
    "else:\n",
    "    lr = LogisticRegression(**lr_params)\n",
    "    lr.fit(X_train, y_train)\n",
    "    joblib.dump(lr, lr_ckpt)\n",
    "    log_step(f\"Saved LR checkpoint: {lr_ckpt}\")\n",
    "log_step_end(\"LR fit\")\n",
    "log_step_end(\"Fold 1/1 (single split)\")\n",
    "print(\"Models trained.\")\n",
    "_gc()\n",
    "log_step_end(\"Train XGBoost and Logistic Regression\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc2efc4",
   "metadata": {},
   "source": [
    "## Calibrate with Platt scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bb4fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start(\"Calibrate with Platt scaling\")\n",
    "calibrated_xgb = CalibratedClassifierCV(xgb, method=\"sigmoid\", cv=\"prefit\")\n",
    "calibrated_xgb.fit(X_valid, y_valid)\n",
    "\n",
    "calibrated_lr = CalibratedClassifierCV(lr, method=\"sigmoid\", cv=\"prefit\")\n",
    "calibrated_lr.fit(X_valid, y_valid)\n",
    "print(\"Models calibrated.\")\n",
    "_gc()\n",
    "log_step_end(\"Calibrate with Platt scaling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcbe065",
   "metadata": {},
   "source": [
    "## Ensemble and threshold tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f830c710",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start(\"Ensemble and threshold tuning\")\n",
    "val_pred_proba_xgb = calibrated_xgb.predict_proba(X_valid)[:, 1]\n",
    "val_pred_proba_lr = calibrated_lr.predict_proba(X_valid)[:, 1]\n",
    "val_pred_proba_ensemble = 0.6 * val_pred_proba_xgb + 0.4 * val_pred_proba_lr\n",
    "\n",
    "thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "best_threshold = 0.5\n",
    "best_f1 = -1.0\n",
    "\n",
    "for thr in thresholds:\n",
    "    val_pred_thr = (val_pred_proba_ensemble >= thr).astype(int)\n",
    "    f1 = f1_score(y_valid, val_pred_thr)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = float(thr)\n",
    "\n",
    "print(f\"Best threshold: {best_threshold:.2f} with F1: {best_f1:.4f}\")\n",
    "log_step_end(\"Ensemble and threshold tuning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91516453",
   "metadata": {},
   "source": [
    "## Validation report and diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b0bdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start(\"Validation report and diagnostics\")\n",
    "val_pred_final = (val_pred_proba_ensemble >= best_threshold).astype(int)\n",
    "print(classification_report(y_valid, val_pred_final))\n",
    "\n",
    "# Diagnostics\n",
    "residual_plot(\n",
    "    y_valid.to_numpy(),\n",
    "    val_pred_proba_ensemble,\n",
    "    \"Residuals: validation ensemble\",\n",
    ")\n",
    "qq_plot(\n",
    "    y_valid.to_numpy() - val_pred_proba_ensemble,\n",
    "    \"QQ plot: residuals (validation)\",\n",
    ")\n",
    "try:\n",
    "    # Violin on a basic feature (train) to visualize label differences\n",
    "    violin_by_label(\n",
    "        train, \"label\", \"text_length\", \"Text length by label (train)\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    warnings.warn(f\"Violin plot skipped: {e}\")\n",
    "log_step_end(\"Validation report and diagnostics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e3f803",
   "metadata": {},
   "source": [
    "## Predict on test and write submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c0fbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step_start(\"Predict on test and write submission\")\n",
    "p_xgb_te = predict_proba_chunks(calibrated_xgb, X_test)\n",
    "p_lr_te = predict_proba_chunks(calibrated_lr, X_test)\n",
    "p_ens_te = 0.6 * p_xgb_te + 0.4 * p_lr_te\n",
    "yhat_te = (p_ens_te >= best_threshold).astype(int)\n",
    "submission = pd.DataFrame({\"id\": test[\"id\"], \"label\": yhat_te})\n",
    "outputs_dir = \"outputs\"\n",
    "os.makedirs(outputs_dir, exist_ok=True)\n",
    "submission_path = os.path.join(outputs_dir, \"submission_hvsm_prod.csv\")\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(\"Saved\", submission_path, \"with\", len(submission), \"rows\")\n",
    "_gc()\n",
    "log_step_end(\"Predict on test and write submission\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
